{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2TfaSFBDUiN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "b5705f40-1f84-409e-f1bc-72e607311704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting huggingface-sb3\n",
            "  Downloading huggingface_sb3-2.2.4-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.7/dist-packages (from huggingface-sb3) (0.10.1)\n",
            "Requirement already satisfied: pyyaml~=6.0 in /usr/local/lib/python3.7/dist-packages (from huggingface-sb3) (6.0)\n",
            "Collecting cloudpickle>=1.6\n",
            "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting huggingface-hub~=0.8\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from huggingface-sb3) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub~=0.8->huggingface-sb3) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub~=0.8->huggingface-sb3) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub~=0.8->huggingface-sb3) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from huggingface-hub~=0.8->huggingface-sb3) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub~=0.8->huggingface-sb3) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub~=0.8->huggingface-sb3) (4.13.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub~=0.8->huggingface-sb3) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub~=0.8->huggingface-sb3) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub~=0.8->huggingface-sb3) (3.0.4)\n",
            "Installing collected packages: huggingface-hub, cloudpickle, huggingface-sb3\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.5.0\n",
            "    Uninstalling cloudpickle-1.5.0:\n",
            "      Successfully uninstalled cloudpickle-1.5.0\n",
            "Successfully installed cloudpickle-2.2.0 huggingface-hub-0.11.1 huggingface-sb3-2.2.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cloudpickle"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!sudo apt-get update > /dev/null 2>&1\n",
        "!sudo apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!pip install rarfile --quiet\n",
        "!pip install stable-baselines3[extra] ale-py==0.7.4 --quiet\n",
        "!pip install box2d-py --quiet\n",
        "!pip install gym pyvirtualdisplay --quiet\n",
        "!pip install pyglet==1.5.27 --quiet\n",
        "!pip install huggingface-sb3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import base64\n",
        "import stable_baselines3\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.results_plotter import ts2xy, load_results\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "from gym.wrappers import Monitor"
      ],
      "metadata": {
        "id": "DGpjpwmEDcTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "# Create the environment\n",
        "env_id = \"LunarLander-v2\"\n",
        "n_envs = 16\n",
        "env = make_vec_env(env_id, n_envs=n_envs)\n",
        "\n",
        "# Create the evaluation envs\n",
        "eval_envs = make_vec_env(env_id, n_envs=5)\n",
        "\n",
        "# Adjust evaluation interval depending on the number of envs\n",
        "eval_freq = int(1e5)\n",
        "eval_freq = max(eval_freq // n_envs, 1)\n",
        "\n",
        "# Create evaluation callback to save best model\n",
        "# and monitor agent performance\n",
        "eval_callback = EvalCallback(\n",
        "    eval_envs,\n",
        "    best_model_save_path=\"./logs/\",\n",
        "    eval_freq=eval_freq,\n",
        "    n_eval_episodes=10,\n",
        ")\n",
        "\n",
        "# Instantiate the agent\n",
        "# Hyperparameters from https://github.com/DLR-RM/rl-baselines3-zoo\n",
        "model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    n_steps=1024,\n",
        "    batch_size=64,\n",
        "    gae_lambda=0.98,\n",
        "    gamma=0.999,\n",
        "    n_epochs=4,\n",
        "    ent_coef=0.01,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Train the agent (you can kill it before using ctrl+c)\n",
        "try:\n",
        "    model.learn(total_timesteps=int(5e6), callback=eval_callback)\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "# Load best model\n",
        "model = PPO.load(\"logs/best_model.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muyKBbnttMg_",
        "outputId": "8ccd0e44-28f7-4518-e6c7-b457ffc1245a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m串流輸出內容已截斷至最後 5000 行。\u001b[0m\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 248         |\n",
            "|    ep_rew_mean          | 272         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 807         |\n",
            "|    iterations           | 85          |\n",
            "|    time_elapsed         | 1725        |\n",
            "|    total_timesteps      | 1392640     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005380973 |\n",
            "|    clip_fraction        | 0.0586      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.714      |\n",
            "|    explained_variance   | 0.996       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.56        |\n",
            "|    n_updates            | 336         |\n",
            "|    policy_gradient_loss | -0.000484   |\n",
            "|    value_loss           | 4.89        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1400000, episode_reward=279.56 +/- 15.83\n",
            "Episode length: 244.80 +/- 15.59\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 245          |\n",
            "|    mean_reward          | 280          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1400000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033222693 |\n",
            "|    clip_fraction        | 0.0447       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.653       |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.57         |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | 0.000135     |\n",
            "|    value_loss           | 5.26         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 252      |\n",
            "|    ep_rew_mean     | 271      |\n",
            "| time/              |          |\n",
            "|    fps             | 810      |\n",
            "|    iterations      | 86       |\n",
            "|    time_elapsed    | 1738     |\n",
            "|    total_timesteps | 1409024  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 249         |\n",
            "|    ep_rew_mean          | 273         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 814         |\n",
            "|    iterations           | 87          |\n",
            "|    time_elapsed         | 1749        |\n",
            "|    total_timesteps      | 1425408     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004074396 |\n",
            "|    clip_fraction        | 0.0404      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.661      |\n",
            "|    explained_variance   | 0.966       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.83        |\n",
            "|    n_updates            | 344         |\n",
            "|    policy_gradient_loss | -7.68e-05   |\n",
            "|    value_loss           | 54.7        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 242          |\n",
            "|    ep_rew_mean          | 273          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 818          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 1760         |\n",
            "|    total_timesteps      | 1441792      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028415523 |\n",
            "|    clip_fraction        | 0.0224       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.655       |\n",
            "|    explained_variance   | 0.943        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 55           |\n",
            "|    n_updates            | 348          |\n",
            "|    policy_gradient_loss | 0.000705     |\n",
            "|    value_loss           | 110          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 238          |\n",
            "|    ep_rew_mean          | 277          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 822          |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 1771         |\n",
            "|    total_timesteps      | 1458176      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030988718 |\n",
            "|    clip_fraction        | 0.037        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.619       |\n",
            "|    explained_variance   | 0.992        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.04         |\n",
            "|    n_updates            | 352          |\n",
            "|    policy_gradient_loss | 0.00155      |\n",
            "|    value_loss           | 10.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 249          |\n",
            "|    ep_rew_mean          | 271          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 826          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 1783         |\n",
            "|    total_timesteps      | 1474560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037342743 |\n",
            "|    clip_fraction        | 0.0485       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.641       |\n",
            "|    explained_variance   | 0.983        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.46         |\n",
            "|    n_updates            | 356          |\n",
            "|    policy_gradient_loss | 0.000798     |\n",
            "|    value_loss           | 33.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 243         |\n",
            "|    ep_rew_mean          | 261         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 830         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 1795        |\n",
            "|    total_timesteps      | 1490944     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004222988 |\n",
            "|    clip_fraction        | 0.0412      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.664      |\n",
            "|    explained_variance   | 0.937       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 14.8        |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | -0.00104    |\n",
            "|    value_loss           | 152         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1500000, episode_reward=268.16 +/- 20.76\n",
            "Episode length: 256.00 +/- 11.16\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 256         |\n",
            "|    mean_reward          | 268         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1500000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004458035 |\n",
            "|    clip_fraction        | 0.0396      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.661      |\n",
            "|    explained_variance   | 0.953       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.49        |\n",
            "|    n_updates            | 364         |\n",
            "|    policy_gradient_loss | 0.000492    |\n",
            "|    value_loss           | 96.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 249      |\n",
            "|    ep_rew_mean     | 276      |\n",
            "| time/              |          |\n",
            "|    fps             | 833      |\n",
            "|    iterations      | 92       |\n",
            "|    time_elapsed    | 1808     |\n",
            "|    total_timesteps | 1507328  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 246          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 837          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 1819         |\n",
            "|    total_timesteps      | 1523712      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041780653 |\n",
            "|    clip_fraction        | 0.0399       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.662       |\n",
            "|    explained_variance   | 0.979        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.82         |\n",
            "|    n_updates            | 368          |\n",
            "|    policy_gradient_loss | 0.00155      |\n",
            "|    value_loss           | 57.6         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 239         |\n",
            "|    ep_rew_mean          | 274         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 841         |\n",
            "|    iterations           | 94          |\n",
            "|    time_elapsed         | 1830        |\n",
            "|    total_timesteps      | 1540096     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003640247 |\n",
            "|    clip_fraction        | 0.0417      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.653      |\n",
            "|    explained_variance   | 0.982       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.28        |\n",
            "|    n_updates            | 372         |\n",
            "|    policy_gradient_loss | 0.000436    |\n",
            "|    value_loss           | 42.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 238         |\n",
            "|    ep_rew_mean          | 279         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 844         |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 1842        |\n",
            "|    total_timesteps      | 1556480     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004036297 |\n",
            "|    clip_fraction        | 0.0555      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.673      |\n",
            "|    explained_variance   | 0.997       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.04        |\n",
            "|    n_updates            | 376         |\n",
            "|    policy_gradient_loss | 0.00132     |\n",
            "|    value_loss           | 4.59        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 236          |\n",
            "|    ep_rew_mean          | 272          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 848          |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 1853         |\n",
            "|    total_timesteps      | 1572864      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036914411 |\n",
            "|    clip_fraction        | 0.0368       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.641       |\n",
            "|    explained_variance   | 0.998        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.16         |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | 0.000641     |\n",
            "|    value_loss           | 3.45         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 234         |\n",
            "|    ep_rew_mean          | 271         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 852         |\n",
            "|    iterations           | 97          |\n",
            "|    time_elapsed         | 1864        |\n",
            "|    total_timesteps      | 1589248     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003516306 |\n",
            "|    clip_fraction        | 0.0275      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.672      |\n",
            "|    explained_variance   | 0.918       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 44.3        |\n",
            "|    n_updates            | 384         |\n",
            "|    policy_gradient_loss | -0.000113   |\n",
            "|    value_loss           | 143         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1600000, episode_reward=286.52 +/- 18.55\n",
            "Episode length: 244.00 +/- 16.91\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 244          |\n",
            "|    mean_reward          | 287          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1600000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024726815 |\n",
            "|    clip_fraction        | 0.0184       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.645       |\n",
            "|    explained_variance   | 0.943        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 34.2         |\n",
            "|    n_updates            | 388          |\n",
            "|    policy_gradient_loss | -0.00033     |\n",
            "|    value_loss           | 117          |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 234      |\n",
            "|    ep_rew_mean     | 270      |\n",
            "| time/              |          |\n",
            "|    fps             | 855      |\n",
            "|    iterations      | 98       |\n",
            "|    time_elapsed    | 1877     |\n",
            "|    total_timesteps | 1605632  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 241          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 858          |\n",
            "|    iterations           | 99           |\n",
            "|    time_elapsed         | 1888         |\n",
            "|    total_timesteps      | 1622016      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037370415 |\n",
            "|    clip_fraction        | 0.0485       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.663       |\n",
            "|    explained_variance   | 0.941        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 109          |\n",
            "|    n_updates            | 392          |\n",
            "|    policy_gradient_loss | 0.00123      |\n",
            "|    value_loss           | 133          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 232          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 862          |\n",
            "|    iterations           | 100          |\n",
            "|    time_elapsed         | 1899         |\n",
            "|    total_timesteps      | 1638400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062147174 |\n",
            "|    clip_fraction        | 0.0738       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.678       |\n",
            "|    explained_variance   | 0.982        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.48         |\n",
            "|    n_updates            | 396          |\n",
            "|    policy_gradient_loss | 0.000392     |\n",
            "|    value_loss           | 33.2         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 243         |\n",
            "|    ep_rew_mean          | 268         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 865         |\n",
            "|    iterations           | 101         |\n",
            "|    time_elapsed         | 1911        |\n",
            "|    total_timesteps      | 1654784     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005213651 |\n",
            "|    clip_fraction        | 0.0331      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.669      |\n",
            "|    explained_variance   | 0.946       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 37.7        |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | 0.000725    |\n",
            "|    value_loss           | 99.7        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 253          |\n",
            "|    ep_rew_mean          | 258          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 869          |\n",
            "|    iterations           | 102          |\n",
            "|    time_elapsed         | 1922         |\n",
            "|    total_timesteps      | 1671168      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061234026 |\n",
            "|    clip_fraction        | 0.0526       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.662       |\n",
            "|    explained_variance   | 0.955        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.68         |\n",
            "|    n_updates            | 404          |\n",
            "|    policy_gradient_loss | 0.000423     |\n",
            "|    value_loss           | 91.8         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 258          |\n",
            "|    ep_rew_mean          | 265          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 872          |\n",
            "|    iterations           | 103          |\n",
            "|    time_elapsed         | 1935         |\n",
            "|    total_timesteps      | 1687552      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036400077 |\n",
            "|    clip_fraction        | 0.0399       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.638       |\n",
            "|    explained_variance   | 0.93         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 98.4         |\n",
            "|    n_updates            | 408          |\n",
            "|    policy_gradient_loss | 0.000247     |\n",
            "|    value_loss           | 208          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1700000, episode_reward=278.06 +/- 15.88\n",
            "Episode length: 250.60 +/- 15.74\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 251         |\n",
            "|    mean_reward          | 278         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1700000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006041984 |\n",
            "|    clip_fraction        | 0.0589      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.661      |\n",
            "|    explained_variance   | 0.964       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 25.5        |\n",
            "|    n_updates            | 412         |\n",
            "|    policy_gradient_loss | 0.000274    |\n",
            "|    value_loss           | 78.5        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 264      |\n",
            "|    ep_rew_mean     | 266      |\n",
            "| time/              |          |\n",
            "|    fps             | 874      |\n",
            "|    iterations      | 104      |\n",
            "|    time_elapsed    | 1948     |\n",
            "|    total_timesteps | 1703936  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 250         |\n",
            "|    ep_rew_mean          | 268         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 877         |\n",
            "|    iterations           | 105         |\n",
            "|    time_elapsed         | 1960        |\n",
            "|    total_timesteps      | 1720320     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003935285 |\n",
            "|    clip_fraction        | 0.049       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.665      |\n",
            "|    explained_variance   | 0.95        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 68.4        |\n",
            "|    n_updates            | 416         |\n",
            "|    policy_gradient_loss | 0.000117    |\n",
            "|    value_loss           | 165         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 244         |\n",
            "|    ep_rew_mean          | 272         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 880         |\n",
            "|    iterations           | 106         |\n",
            "|    time_elapsed         | 1971        |\n",
            "|    total_timesteps      | 1736704     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004496613 |\n",
            "|    clip_fraction        | 0.0621      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.665      |\n",
            "|    explained_variance   | 0.996       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.51        |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | 0.00118     |\n",
            "|    value_loss           | 5.22        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 248         |\n",
            "|    ep_rew_mean          | 268         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 883         |\n",
            "|    iterations           | 107         |\n",
            "|    time_elapsed         | 1983        |\n",
            "|    total_timesteps      | 1753088     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003506702 |\n",
            "|    clip_fraction        | 0.0469      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.655      |\n",
            "|    explained_variance   | 0.962       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 56.7        |\n",
            "|    n_updates            | 424         |\n",
            "|    policy_gradient_loss | 2.66e-05    |\n",
            "|    value_loss           | 104         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 261          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 886          |\n",
            "|    iterations           | 108          |\n",
            "|    time_elapsed         | 1995         |\n",
            "|    total_timesteps      | 1769472      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034570147 |\n",
            "|    clip_fraction        | 0.0284       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.652       |\n",
            "|    explained_variance   | 0.947        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 149          |\n",
            "|    n_updates            | 428          |\n",
            "|    policy_gradient_loss | 0.000231     |\n",
            "|    value_loss           | 156          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 258         |\n",
            "|    ep_rew_mean          | 264         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 889         |\n",
            "|    iterations           | 109         |\n",
            "|    time_elapsed         | 2007        |\n",
            "|    total_timesteps      | 1785856     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005102017 |\n",
            "|    clip_fraction        | 0.0462      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.666      |\n",
            "|    explained_variance   | 0.963       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 39.4        |\n",
            "|    n_updates            | 432         |\n",
            "|    policy_gradient_loss | -0.000217   |\n",
            "|    value_loss           | 95.4        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1800000, episode_reward=281.45 +/- 16.32\n",
            "Episode length: 248.20 +/- 19.78\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 248         |\n",
            "|    mean_reward          | 281         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1800000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003935393 |\n",
            "|    clip_fraction        | 0.0401      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.657      |\n",
            "|    explained_variance   | 0.921       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 332         |\n",
            "|    n_updates            | 436         |\n",
            "|    policy_gradient_loss | -0.000574   |\n",
            "|    value_loss           | 215         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 256      |\n",
            "|    ep_rew_mean     | 271      |\n",
            "| time/              |          |\n",
            "|    fps             | 891      |\n",
            "|    iterations      | 110      |\n",
            "|    time_elapsed    | 2020     |\n",
            "|    total_timesteps | 1802240  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 267         |\n",
            "|    ep_rew_mean          | 276         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 893         |\n",
            "|    iterations           | 111         |\n",
            "|    time_elapsed         | 2036        |\n",
            "|    total_timesteps      | 1818624     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007444815 |\n",
            "|    clip_fraction        | 0.0734      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.667      |\n",
            "|    explained_variance   | 0.992       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.99        |\n",
            "|    n_updates            | 440         |\n",
            "|    policy_gradient_loss | -0.000632   |\n",
            "|    value_loss           | 10.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 248          |\n",
            "|    ep_rew_mean          | 278          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 896          |\n",
            "|    iterations           | 112          |\n",
            "|    time_elapsed         | 2047         |\n",
            "|    total_timesteps      | 1835008      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045161103 |\n",
            "|    clip_fraction        | 0.0457       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.664       |\n",
            "|    explained_variance   | 0.995        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.2          |\n",
            "|    n_updates            | 444          |\n",
            "|    policy_gradient_loss | 0.000289     |\n",
            "|    value_loss           | 8.81         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 243          |\n",
            "|    ep_rew_mean          | 277          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 899          |\n",
            "|    iterations           | 113          |\n",
            "|    time_elapsed         | 2058         |\n",
            "|    total_timesteps      | 1851392      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038761653 |\n",
            "|    clip_fraction        | 0.0303       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.632       |\n",
            "|    explained_variance   | 0.976        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.12         |\n",
            "|    n_updates            | 448          |\n",
            "|    policy_gradient_loss | 0.000764     |\n",
            "|    value_loss           | 60.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 235          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 902          |\n",
            "|    iterations           | 114          |\n",
            "|    time_elapsed         | 2070         |\n",
            "|    total_timesteps      | 1867776      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032580483 |\n",
            "|    clip_fraction        | 0.0344       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.657       |\n",
            "|    explained_variance   | 0.975        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.04         |\n",
            "|    n_updates            | 452          |\n",
            "|    policy_gradient_loss | 0.000844     |\n",
            "|    value_loss           | 53.8         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 234          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 905          |\n",
            "|    iterations           | 115          |\n",
            "|    time_elapsed         | 2081         |\n",
            "|    total_timesteps      | 1884160      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038114467 |\n",
            "|    clip_fraction        | 0.0517       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.636       |\n",
            "|    explained_variance   | 0.985        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.82         |\n",
            "|    n_updates            | 456          |\n",
            "|    policy_gradient_loss | 0.00025      |\n",
            "|    value_loss           | 26.6         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1900000, episode_reward=283.78 +/- 20.46\n",
            "Episode length: 246.90 +/- 11.99\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 247        |\n",
            "|    mean_reward          | 284        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 1900000    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00506558 |\n",
            "|    clip_fraction        | 0.0448     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.66      |\n",
            "|    explained_variance   | 0.96       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.33       |\n",
            "|    n_updates            | 460        |\n",
            "|    policy_gradient_loss | -0.000432  |\n",
            "|    value_loss           | 108        |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 243      |\n",
            "|    ep_rew_mean     | 275      |\n",
            "| time/              |          |\n",
            "|    fps             | 907      |\n",
            "|    iterations      | 116      |\n",
            "|    time_elapsed    | 2094     |\n",
            "|    total_timesteps | 1900544  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 262          |\n",
            "|    ep_rew_mean          | 271          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 909          |\n",
            "|    iterations           | 117          |\n",
            "|    time_elapsed         | 2106         |\n",
            "|    total_timesteps      | 1916928      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035353485 |\n",
            "|    clip_fraction        | 0.0345       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.648       |\n",
            "|    explained_variance   | 0.952        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 443          |\n",
            "|    n_updates            | 464          |\n",
            "|    policy_gradient_loss | 0.000587     |\n",
            "|    value_loss           | 148          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 250         |\n",
            "|    ep_rew_mean          | 276         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 912         |\n",
            "|    iterations           | 118         |\n",
            "|    time_elapsed         | 2117        |\n",
            "|    total_timesteps      | 1933312     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005107004 |\n",
            "|    clip_fraction        | 0.0467      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.625      |\n",
            "|    explained_variance   | 0.969       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.14        |\n",
            "|    n_updates            | 468         |\n",
            "|    policy_gradient_loss | 0.000356    |\n",
            "|    value_loss           | 89.4        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 239          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 915          |\n",
            "|    iterations           | 119          |\n",
            "|    time_elapsed         | 2128         |\n",
            "|    total_timesteps      | 1949696      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033290284 |\n",
            "|    clip_fraction        | 0.0377       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.624       |\n",
            "|    explained_variance   | 0.944        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 395          |\n",
            "|    n_updates            | 472          |\n",
            "|    policy_gradient_loss | 0.000704     |\n",
            "|    value_loss           | 156          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 236         |\n",
            "|    ep_rew_mean          | 272         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 918         |\n",
            "|    iterations           | 120         |\n",
            "|    time_elapsed         | 2139        |\n",
            "|    total_timesteps      | 1966080     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004643838 |\n",
            "|    clip_fraction        | 0.0435      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.639      |\n",
            "|    explained_variance   | 0.983       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.05        |\n",
            "|    n_updates            | 476         |\n",
            "|    policy_gradient_loss | 0.000826    |\n",
            "|    value_loss           | 42.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 234          |\n",
            "|    ep_rew_mean          | 271          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 921          |\n",
            "|    iterations           | 121          |\n",
            "|    time_elapsed         | 2150         |\n",
            "|    total_timesteps      | 1982464      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056169843 |\n",
            "|    clip_fraction        | 0.0553       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.633       |\n",
            "|    explained_variance   | 0.956        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.38         |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | 0.000338     |\n",
            "|    value_loss           | 96           |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 240          |\n",
            "|    ep_rew_mean          | 269          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 924          |\n",
            "|    iterations           | 122          |\n",
            "|    time_elapsed         | 2161         |\n",
            "|    total_timesteps      | 1998848      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047178986 |\n",
            "|    clip_fraction        | 0.0502       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.663       |\n",
            "|    explained_variance   | 0.954        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.92         |\n",
            "|    n_updates            | 484          |\n",
            "|    policy_gradient_loss | 0.000254     |\n",
            "|    value_loss           | 125          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=2000000, episode_reward=270.99 +/- 19.16\n",
            "Episode length: 236.00 +/- 12.99\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 236         |\n",
            "|    mean_reward          | 271         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 2000000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003799053 |\n",
            "|    clip_fraction        | 0.0388      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.645      |\n",
            "|    explained_variance   | 0.936       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 749         |\n",
            "|    n_updates            | 488         |\n",
            "|    policy_gradient_loss | 0.00055     |\n",
            "|    value_loss           | 190         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 246      |\n",
            "|    ep_rew_mean     | 272      |\n",
            "| time/              |          |\n",
            "|    fps             | 926      |\n",
            "|    iterations      | 123      |\n",
            "|    time_elapsed    | 2174     |\n",
            "|    total_timesteps | 2015232  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 239         |\n",
            "|    ep_rew_mean          | 275         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 929         |\n",
            "|    iterations           | 124         |\n",
            "|    time_elapsed         | 2185        |\n",
            "|    total_timesteps      | 2031616     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005030055 |\n",
            "|    clip_fraction        | 0.0552      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.644      |\n",
            "|    explained_variance   | 0.975       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.42        |\n",
            "|    n_updates            | 492         |\n",
            "|    policy_gradient_loss | 0.000671    |\n",
            "|    value_loss           | 50.8        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 229          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 932          |\n",
            "|    iterations           | 125          |\n",
            "|    time_elapsed         | 2196         |\n",
            "|    total_timesteps      | 2048000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038472563 |\n",
            "|    clip_fraction        | 0.0523       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.612       |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.995        |\n",
            "|    n_updates            | 496          |\n",
            "|    policy_gradient_loss | 0.00129      |\n",
            "|    value_loss           | 3.8          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 230          |\n",
            "|    ep_rew_mean          | 276          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 935          |\n",
            "|    iterations           | 126          |\n",
            "|    time_elapsed         | 2206         |\n",
            "|    total_timesteps      | 2064384      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028666295 |\n",
            "|    clip_fraction        | 0.0347       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.602       |\n",
            "|    explained_variance   | 0.956        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.18         |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | 0.000285     |\n",
            "|    value_loss           | 135          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 227          |\n",
            "|    ep_rew_mean          | 277          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 938          |\n",
            "|    iterations           | 127          |\n",
            "|    time_elapsed         | 2217         |\n",
            "|    total_timesteps      | 2080768      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047352146 |\n",
            "|    clip_fraction        | 0.0577       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.612       |\n",
            "|    explained_variance   | 0.973        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 223          |\n",
            "|    n_updates            | 504          |\n",
            "|    policy_gradient_loss | 0.000179     |\n",
            "|    value_loss           | 86.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 224          |\n",
            "|    ep_rew_mean          | 280          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 941          |\n",
            "|    iterations           | 128          |\n",
            "|    time_elapsed         | 2228         |\n",
            "|    total_timesteps      | 2097152      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033058366 |\n",
            "|    clip_fraction        | 0.0368       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.605       |\n",
            "|    explained_variance   | 0.963        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.85         |\n",
            "|    n_updates            | 508          |\n",
            "|    policy_gradient_loss | 0.000921     |\n",
            "|    value_loss           | 80.8         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=2100000, episode_reward=288.20 +/- 17.14\n",
            "Episode length: 232.80 +/- 14.41\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 233          |\n",
            "|    mean_reward          | 288          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2100000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037982562 |\n",
            "|    clip_fraction        | 0.0359       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.599       |\n",
            "|    explained_variance   | 0.98         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.63         |\n",
            "|    n_updates            | 512          |\n",
            "|    policy_gradient_loss | 0.000625     |\n",
            "|    value_loss           | 35.7         |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 229      |\n",
            "|    ep_rew_mean     | 280      |\n",
            "| time/              |          |\n",
            "|    fps             | 943      |\n",
            "|    iterations      | 129      |\n",
            "|    time_elapsed    | 2240     |\n",
            "|    total_timesteps | 2113536  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 223          |\n",
            "|    ep_rew_mean          | 281          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 946          |\n",
            "|    iterations           | 130          |\n",
            "|    time_elapsed         | 2251         |\n",
            "|    total_timesteps      | 2129920      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052759973 |\n",
            "|    clip_fraction        | 0.0431       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.589       |\n",
            "|    explained_variance   | 0.985        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.22         |\n",
            "|    n_updates            | 516          |\n",
            "|    policy_gradient_loss | 0.000902     |\n",
            "|    value_loss           | 25.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 237          |\n",
            "|    ep_rew_mean          | 277          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 948          |\n",
            "|    iterations           | 131          |\n",
            "|    time_elapsed         | 2262         |\n",
            "|    total_timesteps      | 2146304      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035845982 |\n",
            "|    clip_fraction        | 0.051        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.636       |\n",
            "|    explained_variance   | 0.973        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.07         |\n",
            "|    n_updates            | 520          |\n",
            "|    policy_gradient_loss | 0.000727     |\n",
            "|    value_loss           | 77.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 235          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 951          |\n",
            "|    iterations           | 132          |\n",
            "|    time_elapsed         | 2272         |\n",
            "|    total_timesteps      | 2162688      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037932117 |\n",
            "|    clip_fraction        | 0.0476       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.619       |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.18         |\n",
            "|    n_updates            | 524          |\n",
            "|    policy_gradient_loss | 0.000949     |\n",
            "|    value_loss           | 3.96         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 227         |\n",
            "|    ep_rew_mean          | 278         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 954         |\n",
            "|    iterations           | 133         |\n",
            "|    time_elapsed         | 2283        |\n",
            "|    total_timesteps      | 2179072     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002910882 |\n",
            "|    clip_fraction        | 0.0265      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.631      |\n",
            "|    explained_variance   | 0.934       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 13.3        |\n",
            "|    n_updates            | 528         |\n",
            "|    policy_gradient_loss | 6.96e-05    |\n",
            "|    value_loss           | 123         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 224          |\n",
            "|    ep_rew_mean          | 276          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 956          |\n",
            "|    iterations           | 134          |\n",
            "|    time_elapsed         | 2294         |\n",
            "|    total_timesteps      | 2195456      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040781014 |\n",
            "|    clip_fraction        | 0.043        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.62        |\n",
            "|    explained_variance   | 0.971        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.49         |\n",
            "|    n_updates            | 532          |\n",
            "|    policy_gradient_loss | -0.000157    |\n",
            "|    value_loss           | 85.1         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=2200000, episode_reward=280.27 +/- 18.26\n",
            "Episode length: 236.00 +/- 12.62\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 236          |\n",
            "|    mean_reward          | 280          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2200000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038949451 |\n",
            "|    clip_fraction        | 0.0457       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.603       |\n",
            "|    explained_variance   | 0.983        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 76.8         |\n",
            "|    n_updates            | 536          |\n",
            "|    policy_gradient_loss | 0.000771     |\n",
            "|    value_loss           | 42.8         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 225      |\n",
            "|    ep_rew_mean     | 277      |\n",
            "| time/              |          |\n",
            "|    fps             | 958      |\n",
            "|    iterations      | 135      |\n",
            "|    time_elapsed    | 2307     |\n",
            "|    total_timesteps | 2211840  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 243          |\n",
            "|    ep_rew_mean          | 281          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 961          |\n",
            "|    iterations           | 136          |\n",
            "|    time_elapsed         | 2318         |\n",
            "|    total_timesteps      | 2228224      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037426741 |\n",
            "|    clip_fraction        | 0.0389       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.597       |\n",
            "|    explained_variance   | 0.965        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 71.6         |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | 0.000457     |\n",
            "|    value_loss           | 118          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 234          |\n",
            "|    ep_rew_mean          | 281          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 963          |\n",
            "|    iterations           | 137          |\n",
            "|    time_elapsed         | 2329         |\n",
            "|    total_timesteps      | 2244608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036324041 |\n",
            "|    clip_fraction        | 0.055        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.62        |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.73         |\n",
            "|    n_updates            | 544          |\n",
            "|    policy_gradient_loss | 0.00193      |\n",
            "|    value_loss           | 3.64         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 220          |\n",
            "|    ep_rew_mean          | 272          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 966          |\n",
            "|    iterations           | 138          |\n",
            "|    time_elapsed         | 2340         |\n",
            "|    total_timesteps      | 2260992      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036701718 |\n",
            "|    clip_fraction        | 0.0483       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.6         |\n",
            "|    explained_variance   | 0.998        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.33         |\n",
            "|    n_updates            | 548          |\n",
            "|    policy_gradient_loss | 3.37e-05     |\n",
            "|    value_loss           | 3.68         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 235          |\n",
            "|    ep_rew_mean          | 269          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 968          |\n",
            "|    iterations           | 139          |\n",
            "|    time_elapsed         | 2351         |\n",
            "|    total_timesteps      | 2277376      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035966483 |\n",
            "|    clip_fraction        | 0.029        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.629       |\n",
            "|    explained_variance   | 0.959        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 35.4         |\n",
            "|    n_updates            | 552          |\n",
            "|    policy_gradient_loss | 0.000333     |\n",
            "|    value_loss           | 67.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 218          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 971          |\n",
            "|    iterations           | 140          |\n",
            "|    time_elapsed         | 2362         |\n",
            "|    total_timesteps      | 2293760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033380692 |\n",
            "|    clip_fraction        | 0.0376       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.581       |\n",
            "|    explained_variance   | 0.972        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 24.8         |\n",
            "|    n_updates            | 556          |\n",
            "|    policy_gradient_loss | -0.000279    |\n",
            "|    value_loss           | 84           |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=2300000, episode_reward=274.75 +/- 19.30\n",
            "Episode length: 224.40 +/- 12.44\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 224          |\n",
            "|    mean_reward          | 275          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2300000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031399415 |\n",
            "|    clip_fraction        | 0.0263       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.586       |\n",
            "|    explained_variance   | 0.957        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9            |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | 0.000374     |\n",
            "|    value_loss           | 125          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 217      |\n",
            "|    ep_rew_mean     | 276      |\n",
            "| time/              |          |\n",
            "|    fps             | 972      |\n",
            "|    iterations      | 141      |\n",
            "|    time_elapsed    | 2375     |\n",
            "|    total_timesteps | 2310144  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 223          |\n",
            "|    ep_rew_mean          | 282          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 974          |\n",
            "|    iterations           | 142          |\n",
            "|    time_elapsed         | 2388         |\n",
            "|    total_timesteps      | 2326528      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044521797 |\n",
            "|    clip_fraction        | 0.0618       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.602       |\n",
            "|    explained_variance   | 0.979        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 96.8         |\n",
            "|    n_updates            | 564          |\n",
            "|    policy_gradient_loss | 8.22e-05     |\n",
            "|    value_loss           | 47.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 222          |\n",
            "|    ep_rew_mean          | 278          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 976          |\n",
            "|    iterations           | 143          |\n",
            "|    time_elapsed         | 2399         |\n",
            "|    total_timesteps      | 2342912      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044340324 |\n",
            "|    clip_fraction        | 0.0512       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.582       |\n",
            "|    explained_variance   | 0.978        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 33.9         |\n",
            "|    n_updates            | 568          |\n",
            "|    policy_gradient_loss | 0.000531     |\n",
            "|    value_loss           | 34.6         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 244         |\n",
            "|    ep_rew_mean          | 269         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 978         |\n",
            "|    iterations           | 144         |\n",
            "|    time_elapsed         | 2411        |\n",
            "|    total_timesteps      | 2359296     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003706765 |\n",
            "|    clip_fraction        | 0.0495      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.613      |\n",
            "|    explained_variance   | 0.998       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.14        |\n",
            "|    n_updates            | 572         |\n",
            "|    policy_gradient_loss | 0.000525    |\n",
            "|    value_loss           | 3.23        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 240          |\n",
            "|    ep_rew_mean          | 271          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 980          |\n",
            "|    iterations           | 145          |\n",
            "|    time_elapsed         | 2422         |\n",
            "|    total_timesteps      | 2375680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050602937 |\n",
            "|    clip_fraction        | 0.0365       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.676       |\n",
            "|    explained_variance   | 0.946        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 165          |\n",
            "|    n_updates            | 576          |\n",
            "|    policy_gradient_loss | -0.000753    |\n",
            "|    value_loss           | 165          |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 220        |\n",
            "|    ep_rew_mean          | 279        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 983        |\n",
            "|    iterations           | 146        |\n",
            "|    time_elapsed         | 2432       |\n",
            "|    total_timesteps      | 2392064    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00423234 |\n",
            "|    clip_fraction        | 0.047      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.571     |\n",
            "|    explained_variance   | 0.959      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 72.4       |\n",
            "|    n_updates            | 580        |\n",
            "|    policy_gradient_loss | 0.000332   |\n",
            "|    value_loss           | 127        |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=2400000, episode_reward=289.29 +/- 20.09\n",
            "Episode length: 224.20 +/- 11.36\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 224         |\n",
            "|    mean_reward          | 289         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 2400000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004048518 |\n",
            "|    clip_fraction        | 0.0497      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.598      |\n",
            "|    explained_variance   | 0.997       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.02        |\n",
            "|    n_updates            | 584         |\n",
            "|    policy_gradient_loss | 0.000791    |\n",
            "|    value_loss           | 4.27        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 221      |\n",
            "|    ep_rew_mean     | 277      |\n",
            "| time/              |          |\n",
            "|    fps             | 985      |\n",
            "|    iterations      | 147      |\n",
            "|    time_elapsed    | 2444     |\n",
            "|    total_timesteps | 2408448  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 233          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 148          |\n",
            "|    time_elapsed         | 2455         |\n",
            "|    total_timesteps      | 2424832      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032606467 |\n",
            "|    clip_fraction        | 0.038        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.589       |\n",
            "|    explained_variance   | 0.981        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.71         |\n",
            "|    n_updates            | 588          |\n",
            "|    policy_gradient_loss | 0.00154      |\n",
            "|    value_loss           | 67           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 228         |\n",
            "|    ep_rew_mean          | 278         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 989         |\n",
            "|    iterations           | 149         |\n",
            "|    time_elapsed         | 2466        |\n",
            "|    total_timesteps      | 2441216     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003722445 |\n",
            "|    clip_fraction        | 0.0329      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.58       |\n",
            "|    explained_variance   | 0.975       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 51.4        |\n",
            "|    n_updates            | 592         |\n",
            "|    policy_gradient_loss | -0.00024    |\n",
            "|    value_loss           | 72.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 221         |\n",
            "|    ep_rew_mean          | 284         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 991         |\n",
            "|    iterations           | 150         |\n",
            "|    time_elapsed         | 2477        |\n",
            "|    total_timesteps      | 2457600     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004765125 |\n",
            "|    clip_fraction        | 0.0439      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.582      |\n",
            "|    explained_variance   | 0.969       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.59        |\n",
            "|    n_updates            | 596         |\n",
            "|    policy_gradient_loss | 0.000679    |\n",
            "|    value_loss           | 72          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 234          |\n",
            "|    ep_rew_mean          | 284          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 994          |\n",
            "|    iterations           | 151          |\n",
            "|    time_elapsed         | 2488         |\n",
            "|    total_timesteps      | 2473984      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048367386 |\n",
            "|    clip_fraction        | 0.055        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.576       |\n",
            "|    explained_variance   | 0.98         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.64         |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | 0.000747     |\n",
            "|    value_loss           | 72.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 226          |\n",
            "|    ep_rew_mean          | 279          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 996          |\n",
            "|    iterations           | 152          |\n",
            "|    time_elapsed         | 2499         |\n",
            "|    total_timesteps      | 2490368      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037065619 |\n",
            "|    clip_fraction        | 0.054        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.595       |\n",
            "|    explained_variance   | 0.996        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.55         |\n",
            "|    n_updates            | 604          |\n",
            "|    policy_gradient_loss | 0.000893     |\n",
            "|    value_loss           | 7.29         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=2500000, episode_reward=277.78 +/- 18.67\n",
            "Episode length: 216.80 +/- 12.45\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 217         |\n",
            "|    mean_reward          | 278         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 2500000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003303301 |\n",
            "|    clip_fraction        | 0.043       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.569      |\n",
            "|    explained_variance   | 0.978       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.45        |\n",
            "|    n_updates            | 608         |\n",
            "|    policy_gradient_loss | 0.000563    |\n",
            "|    value_loss           | 71.6        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 222      |\n",
            "|    ep_rew_mean     | 279      |\n",
            "| time/              |          |\n",
            "|    fps             | 998      |\n",
            "|    iterations      | 153      |\n",
            "|    time_elapsed    | 2511     |\n",
            "|    total_timesteps | 2506752  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 235         |\n",
            "|    ep_rew_mean          | 271         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1000        |\n",
            "|    iterations           | 154         |\n",
            "|    time_elapsed         | 2522        |\n",
            "|    total_timesteps      | 2523136     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004778468 |\n",
            "|    clip_fraction        | 0.0426      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.606      |\n",
            "|    explained_variance   | 0.98        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.53        |\n",
            "|    n_updates            | 612         |\n",
            "|    policy_gradient_loss | 0.000732    |\n",
            "|    value_loss           | 27.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 225         |\n",
            "|    ep_rew_mean          | 276         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1002        |\n",
            "|    iterations           | 155         |\n",
            "|    time_elapsed         | 2532        |\n",
            "|    total_timesteps      | 2539520     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005432298 |\n",
            "|    clip_fraction        | 0.0641      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.605      |\n",
            "|    explained_variance   | 0.979       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 61          |\n",
            "|    n_updates            | 616         |\n",
            "|    policy_gradient_loss | 0.000555    |\n",
            "|    value_loss           | 67.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 220          |\n",
            "|    ep_rew_mean          | 277          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1004         |\n",
            "|    iterations           | 156          |\n",
            "|    time_elapsed         | 2543         |\n",
            "|    total_timesteps      | 2555904      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037020885 |\n",
            "|    clip_fraction        | 0.054        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.588       |\n",
            "|    explained_variance   | 0.98         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 86.2         |\n",
            "|    n_updates            | 620          |\n",
            "|    policy_gradient_loss | 0.000962     |\n",
            "|    value_loss           | 68.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 234          |\n",
            "|    ep_rew_mean          | 278          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1006         |\n",
            "|    iterations           | 157          |\n",
            "|    time_elapsed         | 2554         |\n",
            "|    total_timesteps      | 2572288      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039486624 |\n",
            "|    clip_fraction        | 0.0469       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.579       |\n",
            "|    explained_variance   | 0.981        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 25.8         |\n",
            "|    n_updates            | 624          |\n",
            "|    policy_gradient_loss | 0.000742     |\n",
            "|    value_loss           | 59.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 227          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1009         |\n",
            "|    iterations           | 158          |\n",
            "|    time_elapsed         | 2565         |\n",
            "|    total_timesteps      | 2588672      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041073775 |\n",
            "|    clip_fraction        | 0.0509       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.561       |\n",
            "|    explained_variance   | 0.994        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.97         |\n",
            "|    n_updates            | 628          |\n",
            "|    policy_gradient_loss | 1.49e-05     |\n",
            "|    value_loss           | 14.1         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=2600000, episode_reward=283.52 +/- 20.19\n",
            "Episode length: 217.20 +/- 7.12\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 217         |\n",
            "|    mean_reward          | 284         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 2600000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003209817 |\n",
            "|    clip_fraction        | 0.0338      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.573      |\n",
            "|    explained_variance   | 0.947       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 86          |\n",
            "|    n_updates            | 632         |\n",
            "|    policy_gradient_loss | 0.000868    |\n",
            "|    value_loss           | 172         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 221      |\n",
            "|    ep_rew_mean     | 282      |\n",
            "| time/              |          |\n",
            "|    fps             | 1010     |\n",
            "|    iterations      | 159      |\n",
            "|    time_elapsed    | 2577     |\n",
            "|    total_timesteps | 2605056  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 217          |\n",
            "|    ep_rew_mean          | 271          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1012         |\n",
            "|    iterations           | 160          |\n",
            "|    time_elapsed         | 2587         |\n",
            "|    total_timesteps      | 2621440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039445153 |\n",
            "|    clip_fraction        | 0.0406       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.551       |\n",
            "|    explained_variance   | 0.959        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.6          |\n",
            "|    n_updates            | 636          |\n",
            "|    policy_gradient_loss | -0.000327    |\n",
            "|    value_loss           | 142          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 225         |\n",
            "|    ep_rew_mean          | 261         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1015        |\n",
            "|    iterations           | 161         |\n",
            "|    time_elapsed         | 2598        |\n",
            "|    total_timesteps      | 2637824     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003920177 |\n",
            "|    clip_fraction        | 0.0416      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.58       |\n",
            "|    explained_variance   | 0.945       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.43        |\n",
            "|    n_updates            | 640         |\n",
            "|    policy_gradient_loss | 0.000847    |\n",
            "|    value_loss           | 190         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 209          |\n",
            "|    ep_rew_mean          | 271          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1017         |\n",
            "|    iterations           | 162          |\n",
            "|    time_elapsed         | 2609         |\n",
            "|    total_timesteps      | 2654208      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032099753 |\n",
            "|    clip_fraction        | 0.0293       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.586       |\n",
            "|    explained_variance   | 0.921        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 69.7         |\n",
            "|    n_updates            | 644          |\n",
            "|    policy_gradient_loss | -0.000627    |\n",
            "|    value_loss           | 291          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 215         |\n",
            "|    ep_rew_mean          | 283         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1019        |\n",
            "|    iterations           | 163         |\n",
            "|    time_elapsed         | 2619        |\n",
            "|    total_timesteps      | 2670592     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005305265 |\n",
            "|    clip_fraction        | 0.0571      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.552      |\n",
            "|    explained_variance   | 0.96        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 139         |\n",
            "|    n_updates            | 648         |\n",
            "|    policy_gradient_loss | 0.0013      |\n",
            "|    value_loss           | 104         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 213         |\n",
            "|    ep_rew_mean          | 271         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1021        |\n",
            "|    iterations           | 164         |\n",
            "|    time_elapsed         | 2629        |\n",
            "|    total_timesteps      | 2686976     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006288955 |\n",
            "|    clip_fraction        | 0.057       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.564      |\n",
            "|    explained_variance   | 0.964       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 29.7        |\n",
            "|    n_updates            | 652         |\n",
            "|    policy_gradient_loss | 0.00125     |\n",
            "|    value_loss           | 114         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=2700000, episode_reward=270.63 +/- 18.91\n",
            "Episode length: 213.00 +/- 8.85\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 213          |\n",
            "|    mean_reward          | 271          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2700000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037977472 |\n",
            "|    clip_fraction        | 0.0466       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.57        |\n",
            "|    explained_variance   | 0.94         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 13.3         |\n",
            "|    n_updates            | 656          |\n",
            "|    policy_gradient_loss | 0.000438     |\n",
            "|    value_loss           | 198          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 225      |\n",
            "|    ep_rew_mean     | 284      |\n",
            "| time/              |          |\n",
            "|    fps             | 1023     |\n",
            "|    iterations      | 165      |\n",
            "|    time_elapsed    | 2642     |\n",
            "|    total_timesteps | 2703360  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 227          |\n",
            "|    ep_rew_mean          | 282          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1025         |\n",
            "|    iterations           | 166          |\n",
            "|    time_elapsed         | 2652         |\n",
            "|    total_timesteps      | 2719744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037757326 |\n",
            "|    clip_fraction        | 0.0544       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.575       |\n",
            "|    explained_variance   | 0.992        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.94         |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | 0.002        |\n",
            "|    value_loss           | 14.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 226          |\n",
            "|    ep_rew_mean          | 276          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1027         |\n",
            "|    iterations           | 167          |\n",
            "|    time_elapsed         | 2663         |\n",
            "|    total_timesteps      | 2736128      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034748577 |\n",
            "|    clip_fraction        | 0.0537       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.58        |\n",
            "|    explained_variance   | 0.988        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.2          |\n",
            "|    n_updates            | 664          |\n",
            "|    policy_gradient_loss | 0.000977     |\n",
            "|    value_loss           | 27.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 220          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1029         |\n",
            "|    iterations           | 168          |\n",
            "|    time_elapsed         | 2673         |\n",
            "|    total_timesteps      | 2752512      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021040742 |\n",
            "|    clip_fraction        | 0.021        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.57        |\n",
            "|    explained_variance   | 0.947        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 120          |\n",
            "|    n_updates            | 668          |\n",
            "|    policy_gradient_loss | 0.000678     |\n",
            "|    value_loss           | 201          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 218          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1031         |\n",
            "|    iterations           | 169          |\n",
            "|    time_elapsed         | 2684         |\n",
            "|    total_timesteps      | 2768896      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033458476 |\n",
            "|    clip_fraction        | 0.0248       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.58        |\n",
            "|    explained_variance   | 0.92         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 21.6         |\n",
            "|    n_updates            | 672          |\n",
            "|    policy_gradient_loss | 2.3e-05      |\n",
            "|    value_loss           | 269          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 217         |\n",
            "|    ep_rew_mean          | 275         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1033        |\n",
            "|    iterations           | 170         |\n",
            "|    time_elapsed         | 2694        |\n",
            "|    total_timesteps      | 2785280     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004873126 |\n",
            "|    clip_fraction        | 0.0626      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.584      |\n",
            "|    explained_variance   | 0.987       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.71        |\n",
            "|    n_updates            | 676         |\n",
            "|    policy_gradient_loss | 0.00125     |\n",
            "|    value_loss           | 35.1        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=2800000, episode_reward=277.65 +/- 17.25\n",
            "Episode length: 215.50 +/- 12.85\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 216          |\n",
            "|    mean_reward          | 278          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2800000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036117625 |\n",
            "|    clip_fraction        | 0.0553       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.568       |\n",
            "|    explained_variance   | 0.987        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.46         |\n",
            "|    n_updates            | 680          |\n",
            "|    policy_gradient_loss | 0.00112      |\n",
            "|    value_loss           | 33.1         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 223      |\n",
            "|    ep_rew_mean     | 269      |\n",
            "| time/              |          |\n",
            "|    fps             | 1035     |\n",
            "|    iterations      | 171      |\n",
            "|    time_elapsed    | 2706     |\n",
            "|    total_timesteps | 2801664  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 219          |\n",
            "|    ep_rew_mean          | 279          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1036         |\n",
            "|    iterations           | 172          |\n",
            "|    time_elapsed         | 2718         |\n",
            "|    total_timesteps      | 2818048      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015953383 |\n",
            "|    clip_fraction        | 0.0158       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.56        |\n",
            "|    explained_variance   | 0.932        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 50.3         |\n",
            "|    n_updates            | 684          |\n",
            "|    policy_gradient_loss | -0.000186    |\n",
            "|    value_loss           | 229          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 214          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1037         |\n",
            "|    iterations           | 173          |\n",
            "|    time_elapsed         | 2731         |\n",
            "|    total_timesteps      | 2834432      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033913353 |\n",
            "|    clip_fraction        | 0.0415       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.541       |\n",
            "|    explained_variance   | 0.947        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 316          |\n",
            "|    n_updates            | 688          |\n",
            "|    policy_gradient_loss | -0.000738    |\n",
            "|    value_loss           | 163          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 220          |\n",
            "|    ep_rew_mean          | 280          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1039         |\n",
            "|    iterations           | 174          |\n",
            "|    time_elapsed         | 2742         |\n",
            "|    total_timesteps      | 2850816      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028063473 |\n",
            "|    clip_fraction        | 0.0347       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.581       |\n",
            "|    explained_variance   | 0.941        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 52.8         |\n",
            "|    n_updates            | 692          |\n",
            "|    policy_gradient_loss | -0.000537    |\n",
            "|    value_loss           | 182          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 214         |\n",
            "|    ep_rew_mean          | 281         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1041        |\n",
            "|    iterations           | 175         |\n",
            "|    time_elapsed         | 2752        |\n",
            "|    total_timesteps      | 2867200     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003909481 |\n",
            "|    clip_fraction        | 0.0611      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.6        |\n",
            "|    explained_variance   | 0.984       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 30.2        |\n",
            "|    n_updates            | 696         |\n",
            "|    policy_gradient_loss | 0.00112     |\n",
            "|    value_loss           | 26.8        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 217          |\n",
            "|    ep_rew_mean          | 283          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1043         |\n",
            "|    iterations           | 176          |\n",
            "|    time_elapsed         | 2763         |\n",
            "|    total_timesteps      | 2883584      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047700885 |\n",
            "|    clip_fraction        | 0.0397       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.553       |\n",
            "|    explained_variance   | 0.962        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 14.7         |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | 0.000647     |\n",
            "|    value_loss           | 124          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 221         |\n",
            "|    ep_rew_mean          | 279         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1045        |\n",
            "|    iterations           | 177         |\n",
            "|    time_elapsed         | 2773        |\n",
            "|    total_timesteps      | 2899968     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005808125 |\n",
            "|    clip_fraction        | 0.0585      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.599      |\n",
            "|    explained_variance   | 0.997       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.53        |\n",
            "|    n_updates            | 704         |\n",
            "|    policy_gradient_loss | 0.0017      |\n",
            "|    value_loss           | 4.91        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=2900000, episode_reward=285.98 +/- 22.19\n",
            "Episode length: 215.40 +/- 11.90\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 215          |\n",
            "|    mean_reward          | 286          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 2900000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037282114 |\n",
            "|    clip_fraction        | 0.0461       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.6         |\n",
            "|    explained_variance   | 0.974        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.45         |\n",
            "|    n_updates            | 708          |\n",
            "|    policy_gradient_loss | 0.00121      |\n",
            "|    value_loss           | 86.1         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 217      |\n",
            "|    ep_rew_mean     | 279      |\n",
            "| time/              |          |\n",
            "|    fps             | 1047     |\n",
            "|    iterations      | 178      |\n",
            "|    time_elapsed    | 2784     |\n",
            "|    total_timesteps | 2916352  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 217         |\n",
            "|    ep_rew_mean          | 285         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1049        |\n",
            "|    iterations           | 179         |\n",
            "|    time_elapsed         | 2794        |\n",
            "|    total_timesteps      | 2932736     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004102965 |\n",
            "|    clip_fraction        | 0.0489      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.571      |\n",
            "|    explained_variance   | 0.981       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.15        |\n",
            "|    n_updates            | 712         |\n",
            "|    policy_gradient_loss | 0.000548    |\n",
            "|    value_loss           | 69.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 212         |\n",
            "|    ep_rew_mean          | 284         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1051        |\n",
            "|    iterations           | 180         |\n",
            "|    time_elapsed         | 2805        |\n",
            "|    total_timesteps      | 2949120     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004622709 |\n",
            "|    clip_fraction        | 0.0526      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.564      |\n",
            "|    explained_variance   | 0.996       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.46        |\n",
            "|    n_updates            | 716         |\n",
            "|    policy_gradient_loss | 0.00123     |\n",
            "|    value_loss           | 6.81        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 226         |\n",
            "|    ep_rew_mean          | 281         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1053        |\n",
            "|    iterations           | 181         |\n",
            "|    time_elapsed         | 2815        |\n",
            "|    total_timesteps      | 2965504     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004371262 |\n",
            "|    clip_fraction        | 0.0341      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.528      |\n",
            "|    explained_variance   | 0.963       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.61        |\n",
            "|    n_updates            | 720         |\n",
            "|    policy_gradient_loss | 0.000473    |\n",
            "|    value_loss           | 89.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 219          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1054         |\n",
            "|    iterations           | 182          |\n",
            "|    time_elapsed         | 2826         |\n",
            "|    total_timesteps      | 2981888      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040150527 |\n",
            "|    clip_fraction        | 0.0474       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.569       |\n",
            "|    explained_variance   | 0.98         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.06         |\n",
            "|    n_updates            | 724          |\n",
            "|    policy_gradient_loss | 0.00112      |\n",
            "|    value_loss           | 56.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 223          |\n",
            "|    ep_rew_mean          | 279          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1056         |\n",
            "|    iterations           | 183          |\n",
            "|    time_elapsed         | 2838         |\n",
            "|    total_timesteps      | 2998272      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040375944 |\n",
            "|    clip_fraction        | 0.0371       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.563       |\n",
            "|    explained_variance   | 0.961        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 24.2         |\n",
            "|    n_updates            | 728          |\n",
            "|    policy_gradient_loss | 0.000591     |\n",
            "|    value_loss           | 138          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3000000, episode_reward=288.35 +/- 15.58\n",
            "Episode length: 221.50 +/- 17.82\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 222         |\n",
            "|    mean_reward          | 288         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3000000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005447846 |\n",
            "|    clip_fraction        | 0.0611      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.564      |\n",
            "|    explained_variance   | 0.99        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 14.7        |\n",
            "|    n_updates            | 732         |\n",
            "|    policy_gradient_loss | 0.000175    |\n",
            "|    value_loss           | 22.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 221      |\n",
            "|    ep_rew_mean     | 281      |\n",
            "| time/              |          |\n",
            "|    fps             | 1056     |\n",
            "|    iterations      | 184      |\n",
            "|    time_elapsed    | 2852     |\n",
            "|    total_timesteps | 3014656  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 225          |\n",
            "|    ep_rew_mean          | 283          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1057         |\n",
            "|    iterations           | 185          |\n",
            "|    time_elapsed         | 2865         |\n",
            "|    total_timesteps      | 3031040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043192045 |\n",
            "|    clip_fraction        | 0.0559       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.583       |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.756        |\n",
            "|    n_updates            | 736          |\n",
            "|    policy_gradient_loss | 0.00105      |\n",
            "|    value_loss           | 4.97         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 222          |\n",
            "|    ep_rew_mean          | 276          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1058         |\n",
            "|    iterations           | 186          |\n",
            "|    time_elapsed         | 2878         |\n",
            "|    total_timesteps      | 3047424      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045525227 |\n",
            "|    clip_fraction        | 0.0448       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.551       |\n",
            "|    explained_variance   | 0.998        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.23         |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | 0.00116      |\n",
            "|    value_loss           | 4.25         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 231         |\n",
            "|    ep_rew_mean          | 273         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1060        |\n",
            "|    iterations           | 187         |\n",
            "|    time_elapsed         | 2890        |\n",
            "|    total_timesteps      | 3063808     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003787838 |\n",
            "|    clip_fraction        | 0.0426      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.608      |\n",
            "|    explained_variance   | 0.98        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.52        |\n",
            "|    n_updates            | 744         |\n",
            "|    policy_gradient_loss | 0.000829    |\n",
            "|    value_loss           | 66          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 213          |\n",
            "|    ep_rew_mean          | 284          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1061         |\n",
            "|    iterations           | 188          |\n",
            "|    time_elapsed         | 2902         |\n",
            "|    total_timesteps      | 3080192      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037609737 |\n",
            "|    clip_fraction        | 0.0359       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.574       |\n",
            "|    explained_variance   | 0.975        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 49.3         |\n",
            "|    n_updates            | 748          |\n",
            "|    policy_gradient_loss | 0.000101     |\n",
            "|    value_loss           | 86.7         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 217         |\n",
            "|    ep_rew_mean          | 269         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1062        |\n",
            "|    iterations           | 189         |\n",
            "|    time_elapsed         | 2914        |\n",
            "|    total_timesteps      | 3096576     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004251833 |\n",
            "|    clip_fraction        | 0.0489      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.565      |\n",
            "|    explained_variance   | 0.998       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.39        |\n",
            "|    n_updates            | 752         |\n",
            "|    policy_gradient_loss | 0.000744    |\n",
            "|    value_loss           | 3.72        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=3100000, episode_reward=287.47 +/- 16.80\n",
            "Episode length: 210.70 +/- 13.43\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 211         |\n",
            "|    mean_reward          | 287         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3100000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003009647 |\n",
            "|    clip_fraction        | 0.0222      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.566      |\n",
            "|    explained_variance   | 0.929       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 49.3        |\n",
            "|    n_updates            | 756         |\n",
            "|    policy_gradient_loss | -1.28e-05   |\n",
            "|    value_loss           | 150         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 213      |\n",
            "|    ep_rew_mean     | 276      |\n",
            "| time/              |          |\n",
            "|    fps             | 1063     |\n",
            "|    iterations      | 190      |\n",
            "|    time_elapsed    | 2927     |\n",
            "|    total_timesteps | 3112960  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 213          |\n",
            "|    ep_rew_mean          | 279          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1064         |\n",
            "|    iterations           | 191          |\n",
            "|    time_elapsed         | 2939         |\n",
            "|    total_timesteps      | 3129344      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052341986 |\n",
            "|    clip_fraction        | 0.0522       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.575       |\n",
            "|    explained_variance   | 0.993        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.32         |\n",
            "|    n_updates            | 760          |\n",
            "|    policy_gradient_loss | 0.000705     |\n",
            "|    value_loss           | 12           |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 212        |\n",
            "|    ep_rew_mean          | 278        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 1065       |\n",
            "|    iterations           | 192        |\n",
            "|    time_elapsed         | 2950       |\n",
            "|    total_timesteps      | 3145728    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00383764 |\n",
            "|    clip_fraction        | 0.0437     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.55      |\n",
            "|    explained_variance   | 0.961      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 29.5       |\n",
            "|    n_updates            | 764        |\n",
            "|    policy_gradient_loss | 0.000445   |\n",
            "|    value_loss           | 119        |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 214        |\n",
            "|    ep_rew_mean          | 280        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 1067       |\n",
            "|    iterations           | 193        |\n",
            "|    time_elapsed         | 2963       |\n",
            "|    total_timesteps      | 3162112    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00319723 |\n",
            "|    clip_fraction        | 0.0387     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.552     |\n",
            "|    explained_variance   | 0.956      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.27       |\n",
            "|    n_updates            | 768        |\n",
            "|    policy_gradient_loss | 9.77e-05   |\n",
            "|    value_loss           | 140        |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 214          |\n",
            "|    ep_rew_mean          | 286          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1068         |\n",
            "|    iterations           | 194          |\n",
            "|    time_elapsed         | 2974         |\n",
            "|    total_timesteps      | 3178496      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039548264 |\n",
            "|    clip_fraction        | 0.0595       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.558       |\n",
            "|    explained_variance   | 0.982        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 199          |\n",
            "|    n_updates            | 772          |\n",
            "|    policy_gradient_loss | 0.00157      |\n",
            "|    value_loss           | 64.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 212          |\n",
            "|    ep_rew_mean          | 283          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1069         |\n",
            "|    iterations           | 195          |\n",
            "|    time_elapsed         | 2986         |\n",
            "|    total_timesteps      | 3194880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031307936 |\n",
            "|    clip_fraction        | 0.0467       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.534       |\n",
            "|    explained_variance   | 0.995        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.727        |\n",
            "|    n_updates            | 776          |\n",
            "|    policy_gradient_loss | 0.00118      |\n",
            "|    value_loss           | 15.4         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3200000, episode_reward=278.24 +/- 20.16\n",
            "Episode length: 212.70 +/- 14.69\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 213         |\n",
            "|    mean_reward          | 278         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3200000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005191071 |\n",
            "|    clip_fraction        | 0.0435      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.547      |\n",
            "|    explained_variance   | 0.981       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.4         |\n",
            "|    n_updates            | 780         |\n",
            "|    policy_gradient_loss | 0.000422    |\n",
            "|    value_loss           | 52.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 221      |\n",
            "|    ep_rew_mean     | 284      |\n",
            "| time/              |          |\n",
            "|    fps             | 1070     |\n",
            "|    iterations      | 196      |\n",
            "|    time_elapsed    | 2998     |\n",
            "|    total_timesteps | 3211264  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 224         |\n",
            "|    ep_rew_mean          | 284         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1071        |\n",
            "|    iterations           | 197         |\n",
            "|    time_elapsed         | 3010        |\n",
            "|    total_timesteps      | 3227648     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004855697 |\n",
            "|    clip_fraction        | 0.043       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.563      |\n",
            "|    explained_variance   | 0.994       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.681       |\n",
            "|    n_updates            | 784         |\n",
            "|    policy_gradient_loss | 0.000557    |\n",
            "|    value_loss           | 13.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 216          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1073         |\n",
            "|    iterations           | 198          |\n",
            "|    time_elapsed         | 3023         |\n",
            "|    total_timesteps      | 3244032      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038882112 |\n",
            "|    clip_fraction        | 0.0432       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.554       |\n",
            "|    explained_variance   | 0.998        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.92         |\n",
            "|    n_updates            | 788          |\n",
            "|    policy_gradient_loss | 0.000719     |\n",
            "|    value_loss           | 3.47         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 214          |\n",
            "|    ep_rew_mean          | 281          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1074         |\n",
            "|    iterations           | 199          |\n",
            "|    time_elapsed         | 3035         |\n",
            "|    total_timesteps      | 3260416      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037548651 |\n",
            "|    clip_fraction        | 0.0315       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.546       |\n",
            "|    explained_variance   | 0.952        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 40.5         |\n",
            "|    n_updates            | 792          |\n",
            "|    policy_gradient_loss | 0.000441     |\n",
            "|    value_loss           | 107          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 214          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1074         |\n",
            "|    iterations           | 200          |\n",
            "|    time_elapsed         | 3049         |\n",
            "|    total_timesteps      | 3276800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034362148 |\n",
            "|    clip_fraction        | 0.0419       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.54        |\n",
            "|    explained_variance   | 0.988        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.47         |\n",
            "|    n_updates            | 796          |\n",
            "|    policy_gradient_loss | 0.000744     |\n",
            "|    value_loss           | 38.1         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 222         |\n",
            "|    ep_rew_mean          | 268         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1074        |\n",
            "|    iterations           | 201         |\n",
            "|    time_elapsed         | 3063        |\n",
            "|    total_timesteps      | 3293184     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003516288 |\n",
            "|    clip_fraction        | 0.0317      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.556      |\n",
            "|    explained_variance   | 0.919       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 13.8        |\n",
            "|    n_updates            | 800         |\n",
            "|    policy_gradient_loss | -0.00112    |\n",
            "|    value_loss           | 271         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=3300000, episode_reward=294.00 +/- 25.14\n",
            "Episode length: 221.70 +/- 14.88\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 222          |\n",
            "|    mean_reward          | 294          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 3300000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036683476 |\n",
            "|    clip_fraction        | 0.041        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.569       |\n",
            "|    explained_variance   | 0.959        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 21.3         |\n",
            "|    n_updates            | 804          |\n",
            "|    policy_gradient_loss | 0.000814     |\n",
            "|    value_loss           | 162          |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 236      |\n",
            "|    ep_rew_mean     | 271      |\n",
            "| time/              |          |\n",
            "|    fps             | 1075     |\n",
            "|    iterations      | 202      |\n",
            "|    time_elapsed    | 3077     |\n",
            "|    total_timesteps | 3309568  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 227          |\n",
            "|    ep_rew_mean          | 267          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1076         |\n",
            "|    iterations           | 203          |\n",
            "|    time_elapsed         | 3090         |\n",
            "|    total_timesteps      | 3325952      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059604296 |\n",
            "|    clip_fraction        | 0.0522       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.558       |\n",
            "|    explained_variance   | 0.967        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 209          |\n",
            "|    n_updates            | 808          |\n",
            "|    policy_gradient_loss | 0.0012       |\n",
            "|    value_loss           | 109          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 212          |\n",
            "|    ep_rew_mean          | 278          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1077         |\n",
            "|    iterations           | 204          |\n",
            "|    time_elapsed         | 3101         |\n",
            "|    total_timesteps      | 3342336      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037711335 |\n",
            "|    clip_fraction        | 0.0464       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.574       |\n",
            "|    explained_variance   | 0.923        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 18.9         |\n",
            "|    n_updates            | 812          |\n",
            "|    policy_gradient_loss | 1.69e-05     |\n",
            "|    value_loss           | 258          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 211         |\n",
            "|    ep_rew_mean          | 276         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1078        |\n",
            "|    iterations           | 205         |\n",
            "|    time_elapsed         | 3113        |\n",
            "|    total_timesteps      | 3358720     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004260064 |\n",
            "|    clip_fraction        | 0.0655      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.535      |\n",
            "|    explained_variance   | 0.986       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.13        |\n",
            "|    n_updates            | 816         |\n",
            "|    policy_gradient_loss | 0.002       |\n",
            "|    value_loss           | 32.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 213         |\n",
            "|    ep_rew_mean          | 280         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1079        |\n",
            "|    iterations           | 206         |\n",
            "|    time_elapsed         | 3125        |\n",
            "|    total_timesteps      | 3375104     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002797658 |\n",
            "|    clip_fraction        | 0.0275      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.55       |\n",
            "|    explained_variance   | 0.94        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 47.3        |\n",
            "|    n_updates            | 820         |\n",
            "|    policy_gradient_loss | -0.000941   |\n",
            "|    value_loss           | 246         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 211          |\n",
            "|    ep_rew_mean          | 272          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1080         |\n",
            "|    iterations           | 207          |\n",
            "|    time_elapsed         | 3137         |\n",
            "|    total_timesteps      | 3391488      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052844025 |\n",
            "|    clip_fraction        | 0.0431       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.539       |\n",
            "|    explained_variance   | 0.941        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2            |\n",
            "|    n_updates            | 824          |\n",
            "|    policy_gradient_loss | 0.000849     |\n",
            "|    value_loss           | 167          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3400000, episode_reward=296.79 +/- 15.06\n",
            "Episode length: 220.20 +/- 13.26\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 220          |\n",
            "|    mean_reward          | 297          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 3400000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050114794 |\n",
            "|    clip_fraction        | 0.0616       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.54        |\n",
            "|    explained_variance   | 0.952        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.74         |\n",
            "|    n_updates            | 828          |\n",
            "|    policy_gradient_loss | 0.000444     |\n",
            "|    value_loss           | 152          |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 211      |\n",
            "|    ep_rew_mean     | 274      |\n",
            "| time/              |          |\n",
            "|    fps             | 1081     |\n",
            "|    iterations      | 208      |\n",
            "|    time_elapsed    | 3150     |\n",
            "|    total_timesteps | 3407872  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 226          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1082         |\n",
            "|    iterations           | 209          |\n",
            "|    time_elapsed         | 3163         |\n",
            "|    total_timesteps      | 3424256      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037207238 |\n",
            "|    clip_fraction        | 0.0466       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.55        |\n",
            "|    explained_variance   | 0.946        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 45           |\n",
            "|    n_updates            | 832          |\n",
            "|    policy_gradient_loss | 0.001        |\n",
            "|    value_loss           | 220          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 209          |\n",
            "|    ep_rew_mean          | 270          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1083         |\n",
            "|    iterations           | 210          |\n",
            "|    time_elapsed         | 3175         |\n",
            "|    total_timesteps      | 3440640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039858012 |\n",
            "|    clip_fraction        | 0.0532       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.554       |\n",
            "|    explained_variance   | 0.963        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7            |\n",
            "|    n_updates            | 836          |\n",
            "|    policy_gradient_loss | 0.000701     |\n",
            "|    value_loss           | 137          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 207          |\n",
            "|    ep_rew_mean          | 268          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1084         |\n",
            "|    iterations           | 211          |\n",
            "|    time_elapsed         | 3187         |\n",
            "|    total_timesteps      | 3457024      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036281983 |\n",
            "|    clip_fraction        | 0.0345       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.563       |\n",
            "|    explained_variance   | 0.921        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 12.7         |\n",
            "|    n_updates            | 840          |\n",
            "|    policy_gradient_loss | 1.49e-05     |\n",
            "|    value_loss           | 266          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 215         |\n",
            "|    ep_rew_mean          | 267         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1085        |\n",
            "|    iterations           | 212         |\n",
            "|    time_elapsed         | 3200        |\n",
            "|    total_timesteps      | 3473408     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004199857 |\n",
            "|    clip_fraction        | 0.0332      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.564      |\n",
            "|    explained_variance   | 0.889       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 104         |\n",
            "|    n_updates            | 844         |\n",
            "|    policy_gradient_loss | -3.94e-05   |\n",
            "|    value_loss           | 386         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 211          |\n",
            "|    ep_rew_mean          | 279          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1086         |\n",
            "|    iterations           | 213          |\n",
            "|    time_elapsed         | 3212         |\n",
            "|    total_timesteps      | 3489792      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0080175055 |\n",
            "|    clip_fraction        | 0.0641       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.561       |\n",
            "|    explained_variance   | 0.944        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 54.9         |\n",
            "|    n_updates            | 848          |\n",
            "|    policy_gradient_loss | 0.000462     |\n",
            "|    value_loss           | 193          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3500000, episode_reward=284.46 +/- 23.12\n",
            "Episode length: 212.00 +/- 14.04\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 212        |\n",
            "|    mean_reward          | 284        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 3500000    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00563332 |\n",
            "|    clip_fraction        | 0.0705     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.554     |\n",
            "|    explained_variance   | 0.984      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 6.96       |\n",
            "|    n_updates            | 852        |\n",
            "|    policy_gradient_loss | 0.00167    |\n",
            "|    value_loss           | 23.6       |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 221      |\n",
            "|    ep_rew_mean     | 282      |\n",
            "| time/              |          |\n",
            "|    fps             | 1086     |\n",
            "|    iterations      | 214      |\n",
            "|    time_elapsed    | 3226     |\n",
            "|    total_timesteps | 3506176  |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 221        |\n",
            "|    ep_rew_mean          | 280        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 1087       |\n",
            "|    iterations           | 215        |\n",
            "|    time_elapsed         | 3239       |\n",
            "|    total_timesteps      | 3522560    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00403664 |\n",
            "|    clip_fraction        | 0.0526     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.553     |\n",
            "|    explained_variance   | 0.99       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 7.82       |\n",
            "|    n_updates            | 856        |\n",
            "|    policy_gradient_loss | 0.00173    |\n",
            "|    value_loss           | 12.3       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 222          |\n",
            "|    ep_rew_mean          | 285          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1088         |\n",
            "|    iterations           | 216          |\n",
            "|    time_elapsed         | 3251         |\n",
            "|    total_timesteps      | 3538944      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036347301 |\n",
            "|    clip_fraction        | 0.0419       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.568       |\n",
            "|    explained_variance   | 0.987        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.09         |\n",
            "|    n_updates            | 860          |\n",
            "|    policy_gradient_loss | 0.00135      |\n",
            "|    value_loss           | 36.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 228          |\n",
            "|    ep_rew_mean          | 283          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1089         |\n",
            "|    iterations           | 217          |\n",
            "|    time_elapsed         | 3264         |\n",
            "|    total_timesteps      | 3555328      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029237182 |\n",
            "|    clip_fraction        | 0.048        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.541       |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.21         |\n",
            "|    n_updates            | 864          |\n",
            "|    policy_gradient_loss | 0.00119      |\n",
            "|    value_loss           | 5.03         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 232          |\n",
            "|    ep_rew_mean          | 274          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1089         |\n",
            "|    iterations           | 218          |\n",
            "|    time_elapsed         | 3277         |\n",
            "|    total_timesteps      | 3571712      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041190097 |\n",
            "|    clip_fraction        | 0.0414       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.527       |\n",
            "|    explained_variance   | 0.984        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.37         |\n",
            "|    n_updates            | 868          |\n",
            "|    policy_gradient_loss | -1.22e-05    |\n",
            "|    value_loss           | 66.6         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 213         |\n",
            "|    ep_rew_mean          | 275         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1090        |\n",
            "|    iterations           | 219         |\n",
            "|    time_elapsed         | 3288        |\n",
            "|    total_timesteps      | 3588096     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004682539 |\n",
            "|    clip_fraction        | 0.0479      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.537      |\n",
            "|    explained_variance   | 0.979       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 11.5        |\n",
            "|    n_updates            | 872         |\n",
            "|    policy_gradient_loss | 0.000444    |\n",
            "|    value_loss           | 53.6        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=3600000, episode_reward=257.11 +/- 84.07\n",
            "Episode length: 201.40 +/- 27.83\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 201          |\n",
            "|    mean_reward          | 257          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 3600000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028061012 |\n",
            "|    clip_fraction        | 0.0248       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.516       |\n",
            "|    explained_variance   | 0.917        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 16.7         |\n",
            "|    n_updates            | 876          |\n",
            "|    policy_gradient_loss | 0.000163     |\n",
            "|    value_loss           | 246          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 204      |\n",
            "|    ep_rew_mean     | 270      |\n",
            "| time/              |          |\n",
            "|    fps             | 1091     |\n",
            "|    iterations      | 220      |\n",
            "|    time_elapsed    | 3301     |\n",
            "|    total_timesteps | 3604480  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 210          |\n",
            "|    ep_rew_mean          | 264          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1092         |\n",
            "|    iterations           | 221          |\n",
            "|    time_elapsed         | 3313         |\n",
            "|    total_timesteps      | 3620864      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029164539 |\n",
            "|    clip_fraction        | 0.0286       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.523       |\n",
            "|    explained_variance   | 0.918        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 18.2         |\n",
            "|    n_updates            | 880          |\n",
            "|    policy_gradient_loss | -0.000561    |\n",
            "|    value_loss           | 302          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 214         |\n",
            "|    ep_rew_mean          | 276         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1093        |\n",
            "|    iterations           | 222         |\n",
            "|    time_elapsed         | 3325        |\n",
            "|    total_timesteps      | 3637248     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004105907 |\n",
            "|    clip_fraction        | 0.0355      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.534      |\n",
            "|    explained_variance   | 0.939       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.72        |\n",
            "|    n_updates            | 884         |\n",
            "|    policy_gradient_loss | 0.000297    |\n",
            "|    value_loss           | 168         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 213         |\n",
            "|    ep_rew_mean          | 265         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1094        |\n",
            "|    iterations           | 223         |\n",
            "|    time_elapsed         | 3338        |\n",
            "|    total_timesteps      | 3653632     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003323573 |\n",
            "|    clip_fraction        | 0.0451      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.499      |\n",
            "|    explained_variance   | 0.969       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 519         |\n",
            "|    n_updates            | 888         |\n",
            "|    policy_gradient_loss | 0.0016      |\n",
            "|    value_loss           | 82.7        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 233          |\n",
            "|    ep_rew_mean          | 265          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1094         |\n",
            "|    iterations           | 224          |\n",
            "|    time_elapsed         | 3352         |\n",
            "|    total_timesteps      | 3670016      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032839177 |\n",
            "|    clip_fraction        | 0.0354       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.533       |\n",
            "|    explained_variance   | 0.936        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.92         |\n",
            "|    n_updates            | 892          |\n",
            "|    policy_gradient_loss | -0.000526    |\n",
            "|    value_loss           | 249          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 238          |\n",
            "|    ep_rew_mean          | 272          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1095         |\n",
            "|    iterations           | 225          |\n",
            "|    time_elapsed         | 3365         |\n",
            "|    total_timesteps      | 3686400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050182464 |\n",
            "|    clip_fraction        | 0.0544       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.53        |\n",
            "|    explained_variance   | 0.974        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.92         |\n",
            "|    n_updates            | 896          |\n",
            "|    policy_gradient_loss | 0.00131      |\n",
            "|    value_loss           | 84.9         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3700000, episode_reward=283.64 +/- 23.09\n",
            "Episode length: 205.20 +/- 8.85\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 205        |\n",
            "|    mean_reward          | 284        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 3700000    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00477946 |\n",
            "|    clip_fraction        | 0.0639     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.536     |\n",
            "|    explained_variance   | 0.961      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 7.01       |\n",
            "|    n_updates            | 900        |\n",
            "|    policy_gradient_loss | 0.00143    |\n",
            "|    value_loss           | 132        |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 208      |\n",
            "|    ep_rew_mean     | 276      |\n",
            "| time/              |          |\n",
            "|    fps             | 1096     |\n",
            "|    iterations      | 226      |\n",
            "|    time_elapsed    | 3378     |\n",
            "|    total_timesteps | 3702784  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 216          |\n",
            "|    ep_rew_mean          | 273          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1096         |\n",
            "|    iterations           | 227          |\n",
            "|    time_elapsed         | 3392         |\n",
            "|    total_timesteps      | 3719168      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033361218 |\n",
            "|    clip_fraction        | 0.0517       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.523       |\n",
            "|    explained_variance   | 0.961        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 200          |\n",
            "|    n_updates            | 904          |\n",
            "|    policy_gradient_loss | 0.000931     |\n",
            "|    value_loss           | 150          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 226         |\n",
            "|    ep_rew_mean          | 275         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1096        |\n",
            "|    iterations           | 228         |\n",
            "|    time_elapsed         | 3406        |\n",
            "|    total_timesteps      | 3735552     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004881284 |\n",
            "|    clip_fraction        | 0.049       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.531      |\n",
            "|    explained_variance   | 0.944       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.95        |\n",
            "|    n_updates            | 908         |\n",
            "|    policy_gradient_loss | -0.00016    |\n",
            "|    value_loss           | 196         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 218          |\n",
            "|    ep_rew_mean          | 280          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1097         |\n",
            "|    iterations           | 229          |\n",
            "|    time_elapsed         | 3419         |\n",
            "|    total_timesteps      | 3751936      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044640745 |\n",
            "|    clip_fraction        | 0.0514       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.543       |\n",
            "|    explained_variance   | 0.989        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.89         |\n",
            "|    n_updates            | 912          |\n",
            "|    policy_gradient_loss | 0.00176      |\n",
            "|    value_loss           | 17.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 209          |\n",
            "|    ep_rew_mean          | 272          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1098         |\n",
            "|    iterations           | 230          |\n",
            "|    time_elapsed         | 3431         |\n",
            "|    total_timesteps      | 3768320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042149667 |\n",
            "|    clip_fraction        | 0.0445       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.54        |\n",
            "|    explained_variance   | 0.977        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.26         |\n",
            "|    n_updates            | 916          |\n",
            "|    policy_gradient_loss | 0.00134      |\n",
            "|    value_loss           | 76.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 210         |\n",
            "|    ep_rew_mean          | 278         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1098        |\n",
            "|    iterations           | 231         |\n",
            "|    time_elapsed         | 3444        |\n",
            "|    total_timesteps      | 3784704     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004926701 |\n",
            "|    clip_fraction        | 0.0365      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.551      |\n",
            "|    explained_variance   | 0.931       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 74.7        |\n",
            "|    n_updates            | 920         |\n",
            "|    policy_gradient_loss | -0.00037    |\n",
            "|    value_loss           | 260         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=3800000, episode_reward=282.16 +/- 17.82\n",
            "Episode length: 226.90 +/- 42.47\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 227         |\n",
            "|    mean_reward          | 282         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 3800000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004832454 |\n",
            "|    clip_fraction        | 0.0646      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.525      |\n",
            "|    explained_variance   | 0.996       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.901       |\n",
            "|    n_updates            | 924         |\n",
            "|    policy_gradient_loss | 0.00176     |\n",
            "|    value_loss           | 5.66        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 220      |\n",
            "|    ep_rew_mean     | 282      |\n",
            "| time/              |          |\n",
            "|    fps             | 1099     |\n",
            "|    iterations      | 232      |\n",
            "|    time_elapsed    | 3458     |\n",
            "|    total_timesteps | 3801088  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 231          |\n",
            "|    ep_rew_mean          | 279          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1099         |\n",
            "|    iterations           | 233          |\n",
            "|    time_elapsed         | 3471         |\n",
            "|    total_timesteps      | 3817472      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035047524 |\n",
            "|    clip_fraction        | 0.0396       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.515       |\n",
            "|    explained_variance   | 0.968        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.88         |\n",
            "|    n_updates            | 928          |\n",
            "|    policy_gradient_loss | 1.38e-05     |\n",
            "|    value_loss           | 119          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 222          |\n",
            "|    ep_rew_mean          | 279          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1100         |\n",
            "|    iterations           | 234          |\n",
            "|    time_elapsed         | 3483         |\n",
            "|    total_timesteps      | 3833856      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041178446 |\n",
            "|    clip_fraction        | 0.044        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.503       |\n",
            "|    explained_variance   | 0.981        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.41         |\n",
            "|    n_updates            | 932          |\n",
            "|    policy_gradient_loss | 0.000883     |\n",
            "|    value_loss           | 73.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 212         |\n",
            "|    ep_rew_mean          | 280         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1101        |\n",
            "|    iterations           | 235         |\n",
            "|    time_elapsed         | 3496        |\n",
            "|    total_timesteps      | 3850240     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004127286 |\n",
            "|    clip_fraction        | 0.0453      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.516      |\n",
            "|    explained_variance   | 0.965       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 176         |\n",
            "|    n_updates            | 936         |\n",
            "|    policy_gradient_loss | 0.00105     |\n",
            "|    value_loss           | 114         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 223         |\n",
            "|    ep_rew_mean          | 282         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1101        |\n",
            "|    iterations           | 236         |\n",
            "|    time_elapsed         | 3509        |\n",
            "|    total_timesteps      | 3866624     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004282239 |\n",
            "|    clip_fraction        | 0.0577      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.551      |\n",
            "|    explained_variance   | 0.979       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.63        |\n",
            "|    n_updates            | 940         |\n",
            "|    policy_gradient_loss | 0.00136     |\n",
            "|    value_loss           | 78.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 220         |\n",
            "|    ep_rew_mean          | 282         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1102        |\n",
            "|    iterations           | 237         |\n",
            "|    time_elapsed         | 3522        |\n",
            "|    total_timesteps      | 3883008     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004325191 |\n",
            "|    clip_fraction        | 0.0521      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.535      |\n",
            "|    explained_variance   | 0.994       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.38        |\n",
            "|    n_updates            | 944         |\n",
            "|    policy_gradient_loss | 0.000757    |\n",
            "|    value_loss           | 9.21        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 224          |\n",
            "|    ep_rew_mean          | 283          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1102         |\n",
            "|    iterations           | 238          |\n",
            "|    time_elapsed         | 3535         |\n",
            "|    total_timesteps      | 3899392      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039153406 |\n",
            "|    clip_fraction        | 0.0538       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.546       |\n",
            "|    explained_variance   | 0.998        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.59         |\n",
            "|    n_updates            | 948          |\n",
            "|    policy_gradient_loss | 0.0012       |\n",
            "|    value_loss           | 4.14         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=3900000, episode_reward=288.37 +/- 19.20\n",
            "Episode length: 211.80 +/- 14.20\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 212          |\n",
            "|    mean_reward          | 288          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 3900000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037705312 |\n",
            "|    clip_fraction        | 0.0486       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.55        |\n",
            "|    explained_variance   | 0.998        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.78         |\n",
            "|    n_updates            | 952          |\n",
            "|    policy_gradient_loss | 0.000927     |\n",
            "|    value_loss           | 3.7          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 220      |\n",
            "|    ep_rew_mean     | 278      |\n",
            "| time/              |          |\n",
            "|    fps             | 1103     |\n",
            "|    iterations      | 239      |\n",
            "|    time_elapsed    | 3549     |\n",
            "|    total_timesteps | 3915776  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 227          |\n",
            "|    ep_rew_mean          | 279          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1103         |\n",
            "|    iterations           | 240          |\n",
            "|    time_elapsed         | 3563         |\n",
            "|    total_timesteps      | 3932160      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029214113 |\n",
            "|    clip_fraction        | 0.0316       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.52        |\n",
            "|    explained_variance   | 0.979        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.6          |\n",
            "|    n_updates            | 956          |\n",
            "|    policy_gradient_loss | 0.000269     |\n",
            "|    value_loss           | 62.6         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 261         |\n",
            "|    ep_rew_mean          | 276         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1103        |\n",
            "|    iterations           | 241         |\n",
            "|    time_elapsed         | 3577        |\n",
            "|    total_timesteps      | 3948544     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004889315 |\n",
            "|    clip_fraction        | 0.0538      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.521      |\n",
            "|    explained_variance   | 0.981       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 133         |\n",
            "|    n_updates            | 960         |\n",
            "|    policy_gradient_loss | 0.000568    |\n",
            "|    value_loss           | 69.2        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 253          |\n",
            "|    ep_rew_mean          | 278          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1104         |\n",
            "|    iterations           | 242          |\n",
            "|    time_elapsed         | 3591         |\n",
            "|    total_timesteps      | 3964928      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059224023 |\n",
            "|    clip_fraction        | 0.0633       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.541       |\n",
            "|    explained_variance   | 0.986        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 23.9         |\n",
            "|    n_updates            | 964          |\n",
            "|    policy_gradient_loss | 0.000497     |\n",
            "|    value_loss           | 44.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 229          |\n",
            "|    ep_rew_mean          | 279          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1104         |\n",
            "|    iterations           | 243          |\n",
            "|    time_elapsed         | 3603         |\n",
            "|    total_timesteps      | 3981312      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047472026 |\n",
            "|    clip_fraction        | 0.0519       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.54        |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.16         |\n",
            "|    n_updates            | 968          |\n",
            "|    policy_gradient_loss | 0.000268     |\n",
            "|    value_loss           | 6.8          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 211          |\n",
            "|    ep_rew_mean          | 281          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1105         |\n",
            "|    iterations           | 244          |\n",
            "|    time_elapsed         | 3616         |\n",
            "|    total_timesteps      | 3997696      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035263416 |\n",
            "|    clip_fraction        | 0.028        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.532       |\n",
            "|    explained_variance   | 0.974        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.739        |\n",
            "|    n_updates            | 972          |\n",
            "|    policy_gradient_loss | 0.000604     |\n",
            "|    value_loss           | 57           |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4000000, episode_reward=285.20 +/- 15.87\n",
            "Episode length: 219.30 +/- 17.73\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 219          |\n",
            "|    mean_reward          | 285          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4000000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046054535 |\n",
            "|    clip_fraction        | 0.0472       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.52        |\n",
            "|    explained_variance   | 0.996        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.51         |\n",
            "|    n_updates            | 976          |\n",
            "|    policy_gradient_loss | 0.000604     |\n",
            "|    value_loss           | 8.11         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 234      |\n",
            "|    ep_rew_mean     | 277      |\n",
            "| time/              |          |\n",
            "|    fps             | 1105     |\n",
            "|    iterations      | 245      |\n",
            "|    time_elapsed    | 3630     |\n",
            "|    total_timesteps | 4014080  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 233          |\n",
            "|    ep_rew_mean          | 279          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1106         |\n",
            "|    iterations           | 246          |\n",
            "|    time_elapsed         | 3643         |\n",
            "|    total_timesteps      | 4030464      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043453714 |\n",
            "|    clip_fraction        | 0.045        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.526       |\n",
            "|    explained_variance   | 0.979        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 245          |\n",
            "|    n_updates            | 980          |\n",
            "|    policy_gradient_loss | 0.00131      |\n",
            "|    value_loss           | 59.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 237          |\n",
            "|    ep_rew_mean          | 281          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1106         |\n",
            "|    iterations           | 247          |\n",
            "|    time_elapsed         | 3657         |\n",
            "|    total_timesteps      | 4046848      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055138026 |\n",
            "|    clip_fraction        | 0.0512       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.513       |\n",
            "|    explained_variance   | 0.984        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 61           |\n",
            "|    n_updates            | 984          |\n",
            "|    policy_gradient_loss | 0.000288     |\n",
            "|    value_loss           | 44.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 219          |\n",
            "|    ep_rew_mean          | 281          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1107         |\n",
            "|    iterations           | 248          |\n",
            "|    time_elapsed         | 3669         |\n",
            "|    total_timesteps      | 4063232      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048305485 |\n",
            "|    clip_fraction        | 0.0474       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.533       |\n",
            "|    explained_variance   | 0.996        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.43         |\n",
            "|    n_updates            | 988          |\n",
            "|    policy_gradient_loss | 0.000798     |\n",
            "|    value_loss           | 8.52         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 211         |\n",
            "|    ep_rew_mean          | 281         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1107        |\n",
            "|    iterations           | 249         |\n",
            "|    time_elapsed         | 3682        |\n",
            "|    total_timesteps      | 4079616     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004479305 |\n",
            "|    clip_fraction        | 0.0613      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.523      |\n",
            "|    explained_variance   | 0.997       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.31        |\n",
            "|    n_updates            | 992         |\n",
            "|    policy_gradient_loss | 0.000202    |\n",
            "|    value_loss           | 5.57        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 209          |\n",
            "|    ep_rew_mean          | 284          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1108         |\n",
            "|    iterations           | 250          |\n",
            "|    time_elapsed         | 3695         |\n",
            "|    total_timesteps      | 4096000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035289838 |\n",
            "|    clip_fraction        | 0.047        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.504       |\n",
            "|    explained_variance   | 0.99         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.57         |\n",
            "|    n_updates            | 996          |\n",
            "|    policy_gradient_loss | 0.00111      |\n",
            "|    value_loss           | 20.9         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4100000, episode_reward=284.99 +/- 17.97\n",
            "Episode length: 209.20 +/- 17.02\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 209         |\n",
            "|    mean_reward          | 285         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 4100000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003933818 |\n",
            "|    clip_fraction        | 0.0393      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.492      |\n",
            "|    explained_variance   | 0.969       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 125         |\n",
            "|    n_updates            | 1000        |\n",
            "|    policy_gradient_loss | 0.000221    |\n",
            "|    value_loss           | 112         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 217      |\n",
            "|    ep_rew_mean     | 287      |\n",
            "| time/              |          |\n",
            "|    fps             | 1108     |\n",
            "|    iterations      | 251      |\n",
            "|    time_elapsed    | 3708     |\n",
            "|    total_timesteps | 4112384  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 214          |\n",
            "|    ep_rew_mean          | 281          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1109         |\n",
            "|    iterations           | 252          |\n",
            "|    time_elapsed         | 3720         |\n",
            "|    total_timesteps      | 4128768      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030475722 |\n",
            "|    clip_fraction        | 0.0424       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.479       |\n",
            "|    explained_variance   | 0.981        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.84         |\n",
            "|    n_updates            | 1004         |\n",
            "|    policy_gradient_loss | 0.00119      |\n",
            "|    value_loss           | 77           |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 210          |\n",
            "|    ep_rew_mean          | 282          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1109         |\n",
            "|    iterations           | 253          |\n",
            "|    time_elapsed         | 3735         |\n",
            "|    total_timesteps      | 4145152      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027555947 |\n",
            "|    clip_fraction        | 0.0515       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.495       |\n",
            "|    explained_variance   | 0.981        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.19         |\n",
            "|    n_updates            | 1008         |\n",
            "|    policy_gradient_loss | 0.000493     |\n",
            "|    value_loss           | 72.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 208          |\n",
            "|    ep_rew_mean          | 288          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1110         |\n",
            "|    iterations           | 254          |\n",
            "|    time_elapsed         | 3748         |\n",
            "|    total_timesteps      | 4161536      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046854964 |\n",
            "|    clip_fraction        | 0.0575       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.491       |\n",
            "|    explained_variance   | 0.988        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.25         |\n",
            "|    n_updates            | 1012         |\n",
            "|    policy_gradient_loss | 0.00114      |\n",
            "|    value_loss           | 25.2         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 211         |\n",
            "|    ep_rew_mean          | 281         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1110        |\n",
            "|    iterations           | 255         |\n",
            "|    time_elapsed         | 3761        |\n",
            "|    total_timesteps      | 4177920     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003552678 |\n",
            "|    clip_fraction        | 0.0426      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.482      |\n",
            "|    explained_variance   | 0.995       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.53        |\n",
            "|    n_updates            | 1016        |\n",
            "|    policy_gradient_loss | 0.00137     |\n",
            "|    value_loss           | 7.94        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 211          |\n",
            "|    ep_rew_mean          | 279          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1111         |\n",
            "|    iterations           | 256          |\n",
            "|    time_elapsed         | 3773         |\n",
            "|    total_timesteps      | 4194304      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034554342 |\n",
            "|    clip_fraction        | 0.0407       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.494       |\n",
            "|    explained_variance   | 0.96         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.29         |\n",
            "|    n_updates            | 1020         |\n",
            "|    policy_gradient_loss | -0.000746    |\n",
            "|    value_loss           | 151          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4200000, episode_reward=286.43 +/- 18.47\n",
            "Episode length: 210.60 +/- 8.58\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 211          |\n",
            "|    mean_reward          | 286          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4200000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035126044 |\n",
            "|    clip_fraction        | 0.0296       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.498       |\n",
            "|    explained_variance   | 0.949        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.25         |\n",
            "|    n_updates            | 1024         |\n",
            "|    policy_gradient_loss | 6.93e-05     |\n",
            "|    value_loss           | 198          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 207      |\n",
            "|    ep_rew_mean     | 278      |\n",
            "| time/              |          |\n",
            "|    fps             | 1112     |\n",
            "|    iterations      | 257      |\n",
            "|    time_elapsed    | 3786     |\n",
            "|    total_timesteps | 4210688  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 208         |\n",
            "|    ep_rew_mean          | 289         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1112        |\n",
            "|    iterations           | 258         |\n",
            "|    time_elapsed         | 3798        |\n",
            "|    total_timesteps      | 4227072     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004704776 |\n",
            "|    clip_fraction        | 0.0566      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.488      |\n",
            "|    explained_variance   | 0.981       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.96        |\n",
            "|    n_updates            | 1028        |\n",
            "|    policy_gradient_loss | 0.00051     |\n",
            "|    value_loss           | 28.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 207          |\n",
            "|    ep_rew_mean          | 286          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1113         |\n",
            "|    iterations           | 259          |\n",
            "|    time_elapsed         | 3810         |\n",
            "|    total_timesteps      | 4243456      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059308154 |\n",
            "|    clip_fraction        | 0.0602       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.489       |\n",
            "|    explained_variance   | 0.994        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.73         |\n",
            "|    n_updates            | 1032         |\n",
            "|    policy_gradient_loss | 0.000752     |\n",
            "|    value_loss           | 7.53         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 205          |\n",
            "|    ep_rew_mean          | 282          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1114         |\n",
            "|    iterations           | 260          |\n",
            "|    time_elapsed         | 3822         |\n",
            "|    total_timesteps      | 4259840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035864813 |\n",
            "|    clip_fraction        | 0.0509       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.482       |\n",
            "|    explained_variance   | 0.998        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.12         |\n",
            "|    n_updates            | 1036         |\n",
            "|    policy_gradient_loss | 0.00119      |\n",
            "|    value_loss           | 2.37         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 206         |\n",
            "|    ep_rew_mean          | 280         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1115        |\n",
            "|    iterations           | 261         |\n",
            "|    time_elapsed         | 3833        |\n",
            "|    total_timesteps      | 4276224     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002957138 |\n",
            "|    clip_fraction        | 0.0372      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.498      |\n",
            "|    explained_variance   | 0.991       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.718       |\n",
            "|    n_updates            | 1040        |\n",
            "|    policy_gradient_loss | 0.000448    |\n",
            "|    value_loss           | 20.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 208          |\n",
            "|    ep_rew_mean          | 279          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1116         |\n",
            "|    iterations           | 262          |\n",
            "|    time_elapsed         | 3844         |\n",
            "|    total_timesteps      | 4292608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025095684 |\n",
            "|    clip_fraction        | 0.0258       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.475       |\n",
            "|    explained_variance   | 0.958        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.49         |\n",
            "|    n_updates            | 1044         |\n",
            "|    policy_gradient_loss | -8.43e-05    |\n",
            "|    value_loss           | 157          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4300000, episode_reward=288.01 +/- 8.30\n",
            "Episode length: 203.20 +/- 15.90\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 203        |\n",
            "|    mean_reward          | 288        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 4300000    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00447733 |\n",
            "|    clip_fraction        | 0.0481     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.482     |\n",
            "|    explained_variance   | 0.983      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 157        |\n",
            "|    n_updates            | 1048       |\n",
            "|    policy_gradient_loss | 0.000413   |\n",
            "|    value_loss           | 67         |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 211      |\n",
            "|    ep_rew_mean     | 279      |\n",
            "| time/              |          |\n",
            "|    fps             | 1117     |\n",
            "|    iterations      | 263      |\n",
            "|    time_elapsed    | 3856     |\n",
            "|    total_timesteps | 4308992  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 211          |\n",
            "|    ep_rew_mean          | 278          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1118         |\n",
            "|    iterations           | 264          |\n",
            "|    time_elapsed         | 3867         |\n",
            "|    total_timesteps      | 4325376      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034773042 |\n",
            "|    clip_fraction        | 0.0362       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.491       |\n",
            "|    explained_variance   | 0.962        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.93         |\n",
            "|    n_updates            | 1052         |\n",
            "|    policy_gradient_loss | -0.000176    |\n",
            "|    value_loss           | 134          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 203          |\n",
            "|    ep_rew_mean          | 276          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1119         |\n",
            "|    iterations           | 265          |\n",
            "|    time_elapsed         | 3878         |\n",
            "|    total_timesteps      | 4341760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038307547 |\n",
            "|    clip_fraction        | 0.0606       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.487       |\n",
            "|    explained_variance   | 0.985        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.47         |\n",
            "|    n_updates            | 1056         |\n",
            "|    policy_gradient_loss | 0.002        |\n",
            "|    value_loss           | 54.3         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 220         |\n",
            "|    ep_rew_mean          | 272         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1120        |\n",
            "|    iterations           | 266         |\n",
            "|    time_elapsed         | 3890        |\n",
            "|    total_timesteps      | 4358144     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002773338 |\n",
            "|    clip_fraction        | 0.0339      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.499      |\n",
            "|    explained_variance   | 0.948       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 17.9        |\n",
            "|    n_updates            | 1060        |\n",
            "|    policy_gradient_loss | -0.000965   |\n",
            "|    value_loss           | 148         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 215         |\n",
            "|    ep_rew_mean          | 281         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1121        |\n",
            "|    iterations           | 267         |\n",
            "|    time_elapsed         | 3901        |\n",
            "|    total_timesteps      | 4374528     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002881112 |\n",
            "|    clip_fraction        | 0.0282      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.487      |\n",
            "|    explained_variance   | 0.971       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.82        |\n",
            "|    n_updates            | 1064        |\n",
            "|    policy_gradient_loss | 0.00103     |\n",
            "|    value_loss           | 125         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 217         |\n",
            "|    ep_rew_mean          | 277         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1122        |\n",
            "|    iterations           | 268         |\n",
            "|    time_elapsed         | 3913        |\n",
            "|    total_timesteps      | 4390912     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002937105 |\n",
            "|    clip_fraction        | 0.0429      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.483      |\n",
            "|    explained_variance   | 0.984       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 14          |\n",
            "|    n_updates            | 1068        |\n",
            "|    policy_gradient_loss | 0.000722    |\n",
            "|    value_loss           | 26.9        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=4400000, episode_reward=280.75 +/- 20.62\n",
            "Episode length: 204.50 +/- 11.58\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 204          |\n",
            "|    mean_reward          | 281          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4400000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069950563 |\n",
            "|    clip_fraction        | 0.0532       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.484       |\n",
            "|    explained_variance   | 0.972        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 108          |\n",
            "|    n_updates            | 1072         |\n",
            "|    policy_gradient_loss | 0.0017       |\n",
            "|    value_loss           | 82.8         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 207      |\n",
            "|    ep_rew_mean     | 284      |\n",
            "| time/              |          |\n",
            "|    fps             | 1123     |\n",
            "|    iterations      | 269      |\n",
            "|    time_elapsed    | 3924     |\n",
            "|    total_timesteps | 4407296  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 205          |\n",
            "|    ep_rew_mean          | 285          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1124         |\n",
            "|    iterations           | 270          |\n",
            "|    time_elapsed         | 3935         |\n",
            "|    total_timesteps      | 4423680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039528073 |\n",
            "|    clip_fraction        | 0.05         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.479       |\n",
            "|    explained_variance   | 0.999        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.48         |\n",
            "|    n_updates            | 1076         |\n",
            "|    policy_gradient_loss | 0.00116      |\n",
            "|    value_loss           | 2.06         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 202         |\n",
            "|    ep_rew_mean          | 281         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1125        |\n",
            "|    iterations           | 271         |\n",
            "|    time_elapsed         | 3945        |\n",
            "|    total_timesteps      | 4440064     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002878603 |\n",
            "|    clip_fraction        | 0.0347      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.475      |\n",
            "|    explained_variance   | 0.982       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.9         |\n",
            "|    n_updates            | 1080        |\n",
            "|    policy_gradient_loss | 0.000508    |\n",
            "|    value_loss           | 71.1        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 209          |\n",
            "|    ep_rew_mean          | 283          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1126         |\n",
            "|    iterations           | 272          |\n",
            "|    time_elapsed         | 3956         |\n",
            "|    total_timesteps      | 4456448      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033505228 |\n",
            "|    clip_fraction        | 0.0391       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.488       |\n",
            "|    explained_variance   | 0.98         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.05         |\n",
            "|    n_updates            | 1084         |\n",
            "|    policy_gradient_loss | 0.000567     |\n",
            "|    value_loss           | 32.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 203          |\n",
            "|    ep_rew_mean          | 282          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1127         |\n",
            "|    iterations           | 273          |\n",
            "|    time_elapsed         | 3967         |\n",
            "|    total_timesteps      | 4472832      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040558074 |\n",
            "|    clip_fraction        | 0.048        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.484       |\n",
            "|    explained_variance   | 0.98         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.62         |\n",
            "|    n_updates            | 1088         |\n",
            "|    policy_gradient_loss | 0.000423     |\n",
            "|    value_loss           | 61.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 201          |\n",
            "|    ep_rew_mean          | 272          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1128         |\n",
            "|    iterations           | 274          |\n",
            "|    time_elapsed         | 3979         |\n",
            "|    total_timesteps      | 4489216      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022911252 |\n",
            "|    clip_fraction        | 0.0191       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.441       |\n",
            "|    explained_variance   | 0.967        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.5          |\n",
            "|    n_updates            | 1092         |\n",
            "|    policy_gradient_loss | 0.00129      |\n",
            "|    value_loss           | 124          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4500000, episode_reward=279.61 +/- 23.37\n",
            "Episode length: 205.50 +/- 13.37\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 206          |\n",
            "|    mean_reward          | 280          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4500000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023244554 |\n",
            "|    clip_fraction        | 0.0262       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.487       |\n",
            "|    explained_variance   | 0.937        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 23.8         |\n",
            "|    n_updates            | 1096         |\n",
            "|    policy_gradient_loss | 0.000122     |\n",
            "|    value_loss           | 245          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 205      |\n",
            "|    ep_rew_mean     | 284      |\n",
            "| time/              |          |\n",
            "|    fps             | 1128     |\n",
            "|    iterations      | 275      |\n",
            "|    time_elapsed    | 3990     |\n",
            "|    total_timesteps | 4505600  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 204         |\n",
            "|    ep_rew_mean          | 283         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1130        |\n",
            "|    iterations           | 276         |\n",
            "|    time_elapsed         | 4001        |\n",
            "|    total_timesteps      | 4521984     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004405141 |\n",
            "|    clip_fraction        | 0.0599      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.475      |\n",
            "|    explained_variance   | 0.998       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.25        |\n",
            "|    n_updates            | 1100        |\n",
            "|    policy_gradient_loss | 0.00146     |\n",
            "|    value_loss           | 3.63        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 202          |\n",
            "|    ep_rew_mean          | 283          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1131         |\n",
            "|    iterations           | 277          |\n",
            "|    time_elapsed         | 4011         |\n",
            "|    total_timesteps      | 4538368      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042358954 |\n",
            "|    clip_fraction        | 0.0475       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.464       |\n",
            "|    explained_variance   | 0.979        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.323        |\n",
            "|    n_updates            | 1104         |\n",
            "|    policy_gradient_loss | 0.000723     |\n",
            "|    value_loss           | 25.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 209          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1132         |\n",
            "|    iterations           | 278          |\n",
            "|    time_elapsed         | 4022         |\n",
            "|    total_timesteps      | 4554752      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045199394 |\n",
            "|    clip_fraction        | 0.0424       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.476       |\n",
            "|    explained_variance   | 0.978        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 134          |\n",
            "|    n_updates            | 1108         |\n",
            "|    policy_gradient_loss | 0.000362     |\n",
            "|    value_loss           | 80.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 205          |\n",
            "|    ep_rew_mean          | 280          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1133         |\n",
            "|    iterations           | 279          |\n",
            "|    time_elapsed         | 4032         |\n",
            "|    total_timesteps      | 4571136      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034516621 |\n",
            "|    clip_fraction        | 0.0319       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.483       |\n",
            "|    explained_variance   | 0.957        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.2          |\n",
            "|    n_updates            | 1112         |\n",
            "|    policy_gradient_loss | 0.000604     |\n",
            "|    value_loss           | 169          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 208         |\n",
            "|    ep_rew_mean          | 283         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1134        |\n",
            "|    iterations           | 280         |\n",
            "|    time_elapsed         | 4043        |\n",
            "|    total_timesteps      | 4587520     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005394267 |\n",
            "|    clip_fraction        | 0.0599      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.484      |\n",
            "|    explained_variance   | 0.976       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.36        |\n",
            "|    n_updates            | 1116        |\n",
            "|    policy_gradient_loss | 6.98e-06    |\n",
            "|    value_loss           | 77.7        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=4600000, episode_reward=286.10 +/- 22.64\n",
            "Episode length: 202.60 +/- 8.03\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 203         |\n",
            "|    mean_reward          | 286         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 4600000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005195498 |\n",
            "|    clip_fraction        | 0.0647      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.476      |\n",
            "|    explained_variance   | 0.997       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.755       |\n",
            "|    n_updates            | 1120        |\n",
            "|    policy_gradient_loss | 0.00187     |\n",
            "|    value_loss           | 3.5         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 215      |\n",
            "|    ep_rew_mean     | 285      |\n",
            "| time/              |          |\n",
            "|    fps             | 1135     |\n",
            "|    iterations      | 281      |\n",
            "|    time_elapsed    | 4055     |\n",
            "|    total_timesteps | 4603904  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 219         |\n",
            "|    ep_rew_mean          | 279         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1136        |\n",
            "|    iterations           | 282         |\n",
            "|    time_elapsed         | 4066        |\n",
            "|    total_timesteps      | 4620288     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003917793 |\n",
            "|    clip_fraction        | 0.0336      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.487      |\n",
            "|    explained_variance   | 0.977       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.55        |\n",
            "|    n_updates            | 1124        |\n",
            "|    policy_gradient_loss | 0.00155     |\n",
            "|    value_loss           | 88.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 204         |\n",
            "|    ep_rew_mean          | 281         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1137        |\n",
            "|    iterations           | 283         |\n",
            "|    time_elapsed         | 4076        |\n",
            "|    total_timesteps      | 4636672     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003197917 |\n",
            "|    clip_fraction        | 0.0342      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.481      |\n",
            "|    explained_variance   | 0.969       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.28        |\n",
            "|    n_updates            | 1128        |\n",
            "|    policy_gradient_loss | 0.000743    |\n",
            "|    value_loss           | 63.7        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 207          |\n",
            "|    ep_rew_mean          | 283          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1138         |\n",
            "|    iterations           | 284          |\n",
            "|    time_elapsed         | 4087         |\n",
            "|    total_timesteps      | 4653056      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045610536 |\n",
            "|    clip_fraction        | 0.0457       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.461       |\n",
            "|    explained_variance   | 0.98         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.37         |\n",
            "|    n_updates            | 1132         |\n",
            "|    policy_gradient_loss | 0.000807     |\n",
            "|    value_loss           | 69.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 203          |\n",
            "|    ep_rew_mean          | 281          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1139         |\n",
            "|    iterations           | 285          |\n",
            "|    time_elapsed         | 4097         |\n",
            "|    total_timesteps      | 4669440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043262197 |\n",
            "|    clip_fraction        | 0.0423       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.471       |\n",
            "|    explained_variance   | 0.972        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.81         |\n",
            "|    n_updates            | 1136         |\n",
            "|    policy_gradient_loss | 0.000562     |\n",
            "|    value_loss           | 101          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 206          |\n",
            "|    ep_rew_mean          | 289          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1140         |\n",
            "|    iterations           | 286          |\n",
            "|    time_elapsed         | 4107         |\n",
            "|    total_timesteps      | 4685824      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046794526 |\n",
            "|    clip_fraction        | 0.0607       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.462       |\n",
            "|    explained_variance   | 0.973        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.32         |\n",
            "|    n_updates            | 1140         |\n",
            "|    policy_gradient_loss | 0.00155      |\n",
            "|    value_loss           | 60.3         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4700000, episode_reward=275.71 +/- 20.02\n",
            "Episode length: 203.50 +/- 12.07\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 204          |\n",
            "|    mean_reward          | 276          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4700000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045298627 |\n",
            "|    clip_fraction        | 0.0538       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.459       |\n",
            "|    explained_variance   | 0.984        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.28         |\n",
            "|    n_updates            | 1144         |\n",
            "|    policy_gradient_loss | 0.00121      |\n",
            "|    value_loss           | 15.1         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 209      |\n",
            "|    ep_rew_mean     | 284      |\n",
            "| time/              |          |\n",
            "|    fps             | 1141     |\n",
            "|    iterations      | 287      |\n",
            "|    time_elapsed    | 4119     |\n",
            "|    total_timesteps | 4702208  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 220          |\n",
            "|    ep_rew_mean          | 277          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1142         |\n",
            "|    iterations           | 288          |\n",
            "|    time_elapsed         | 4130         |\n",
            "|    total_timesteps      | 4718592      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040435875 |\n",
            "|    clip_fraction        | 0.0438       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.488       |\n",
            "|    explained_variance   | 0.995        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.36         |\n",
            "|    n_updates            | 1148         |\n",
            "|    policy_gradient_loss | 0.00215      |\n",
            "|    value_loss           | 6.56         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 207          |\n",
            "|    ep_rew_mean          | 284          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1143         |\n",
            "|    iterations           | 289          |\n",
            "|    time_elapsed         | 4140         |\n",
            "|    total_timesteps      | 4734976      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037590726 |\n",
            "|    clip_fraction        | 0.034        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.477       |\n",
            "|    explained_variance   | 0.969        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.977        |\n",
            "|    n_updates            | 1152         |\n",
            "|    policy_gradient_loss | 0.00122      |\n",
            "|    value_loss           | 139          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 206         |\n",
            "|    ep_rew_mean          | 280         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1144        |\n",
            "|    iterations           | 290         |\n",
            "|    time_elapsed         | 4151        |\n",
            "|    total_timesteps      | 4751360     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003550947 |\n",
            "|    clip_fraction        | 0.0376      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.454      |\n",
            "|    explained_variance   | 0.976       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.26        |\n",
            "|    n_updates            | 1156        |\n",
            "|    policy_gradient_loss | 0.00115     |\n",
            "|    value_loss           | 41.4        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 206          |\n",
            "|    ep_rew_mean          | 283          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1145         |\n",
            "|    iterations           | 291          |\n",
            "|    time_elapsed         | 4161         |\n",
            "|    total_timesteps      | 4767744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042017037 |\n",
            "|    clip_fraction        | 0.0509       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.469       |\n",
            "|    explained_variance   | 0.967        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 34.1         |\n",
            "|    n_updates            | 1160         |\n",
            "|    policy_gradient_loss | 0.00067      |\n",
            "|    value_loss           | 122          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 214          |\n",
            "|    ep_rew_mean          | 276          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1146         |\n",
            "|    iterations           | 292          |\n",
            "|    time_elapsed         | 4172         |\n",
            "|    total_timesteps      | 4784128      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043070884 |\n",
            "|    clip_fraction        | 0.0491       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.474       |\n",
            "|    explained_variance   | 0.997        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.48         |\n",
            "|    n_updates            | 1164         |\n",
            "|    policy_gradient_loss | 0.00203      |\n",
            "|    value_loss           | 5.59         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4800000, episode_reward=287.20 +/- 18.44\n",
            "Episode length: 200.90 +/- 17.65\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 201          |\n",
            "|    mean_reward          | 287          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4800000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030551704 |\n",
            "|    clip_fraction        | 0.0281       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.452       |\n",
            "|    explained_variance   | 0.954        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 64.8         |\n",
            "|    n_updates            | 1168         |\n",
            "|    policy_gradient_loss | -0.000215    |\n",
            "|    value_loss           | 135          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 201      |\n",
            "|    ep_rew_mean     | 279      |\n",
            "| time/              |          |\n",
            "|    fps             | 1147     |\n",
            "|    iterations      | 293      |\n",
            "|    time_elapsed    | 4183     |\n",
            "|    total_timesteps | 4800512  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 201          |\n",
            "|    ep_rew_mean          | 280          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1148         |\n",
            "|    iterations           | 294          |\n",
            "|    time_elapsed         | 4193         |\n",
            "|    total_timesteps      | 4816896      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034672918 |\n",
            "|    clip_fraction        | 0.049        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.467       |\n",
            "|    explained_variance   | 0.961        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.34         |\n",
            "|    n_updates            | 1172         |\n",
            "|    policy_gradient_loss | 0.00099      |\n",
            "|    value_loss           | 149          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 199         |\n",
            "|    ep_rew_mean          | 284         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1149        |\n",
            "|    iterations           | 295         |\n",
            "|    time_elapsed         | 4203        |\n",
            "|    total_timesteps      | 4833280     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004811136 |\n",
            "|    clip_fraction        | 0.0587      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.457      |\n",
            "|    explained_variance   | 0.984       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.45        |\n",
            "|    n_updates            | 1176        |\n",
            "|    policy_gradient_loss | 0.00124     |\n",
            "|    value_loss           | 26.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 207         |\n",
            "|    ep_rew_mean          | 279         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1150        |\n",
            "|    iterations           | 296         |\n",
            "|    time_elapsed         | 4215        |\n",
            "|    total_timesteps      | 4849664     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004353466 |\n",
            "|    clip_fraction        | 0.0443      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.463      |\n",
            "|    explained_variance   | 0.965       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.41        |\n",
            "|    n_updates            | 1180        |\n",
            "|    policy_gradient_loss | 0.000289    |\n",
            "|    value_loss           | 106         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 220          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1151         |\n",
            "|    iterations           | 297          |\n",
            "|    time_elapsed         | 4226         |\n",
            "|    total_timesteps      | 4866048      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039654635 |\n",
            "|    clip_fraction        | 0.0301       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.461       |\n",
            "|    explained_variance   | 0.96         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 37.9         |\n",
            "|    n_updates            | 1184         |\n",
            "|    policy_gradient_loss | 0.000337     |\n",
            "|    value_loss           | 149          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 232         |\n",
            "|    ep_rew_mean          | 286         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1152        |\n",
            "|    iterations           | 298         |\n",
            "|    time_elapsed         | 4237        |\n",
            "|    total_timesteps      | 4882432     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005047828 |\n",
            "|    clip_fraction        | 0.0497      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.485      |\n",
            "|    explained_variance   | 0.956       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.47        |\n",
            "|    n_updates            | 1188        |\n",
            "|    policy_gradient_loss | 0.00078     |\n",
            "|    value_loss           | 155         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 212          |\n",
            "|    ep_rew_mean          | 281          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1153         |\n",
            "|    iterations           | 299          |\n",
            "|    time_elapsed         | 4246         |\n",
            "|    total_timesteps      | 4898816      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034742386 |\n",
            "|    clip_fraction        | 0.0517       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.467       |\n",
            "|    explained_variance   | 0.995        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.12         |\n",
            "|    n_updates            | 1192         |\n",
            "|    policy_gradient_loss | 0.00166      |\n",
            "|    value_loss           | 10.6         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=4900000, episode_reward=273.80 +/- 17.29\n",
            "Episode length: 205.20 +/- 14.93\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 205          |\n",
            "|    mean_reward          | 274          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 4900000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035554776 |\n",
            "|    clip_fraction        | 0.0393       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.458       |\n",
            "|    explained_variance   | 0.963        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 29           |\n",
            "|    n_updates            | 1196         |\n",
            "|    policy_gradient_loss | 0.000548     |\n",
            "|    value_loss           | 136          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 198      |\n",
            "|    ep_rew_mean     | 279      |\n",
            "| time/              |          |\n",
            "|    fps             | 1154     |\n",
            "|    iterations      | 300      |\n",
            "|    time_elapsed    | 4257     |\n",
            "|    total_timesteps | 4915200  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | 279          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1155         |\n",
            "|    iterations           | 301          |\n",
            "|    time_elapsed         | 4267         |\n",
            "|    total_timesteps      | 4931584      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032126862 |\n",
            "|    clip_fraction        | 0.0472       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.464       |\n",
            "|    explained_variance   | 0.966        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 270          |\n",
            "|    n_updates            | 1200         |\n",
            "|    policy_gradient_loss | 0.000661     |\n",
            "|    value_loss           | 138          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 199          |\n",
            "|    ep_rew_mean          | 276          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1156         |\n",
            "|    iterations           | 302          |\n",
            "|    time_elapsed         | 4276         |\n",
            "|    total_timesteps      | 4947968      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044898014 |\n",
            "|    clip_fraction        | 0.0579       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.462       |\n",
            "|    explained_variance   | 0.982        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.17         |\n",
            "|    n_updates            | 1204         |\n",
            "|    policy_gradient_loss | 0.00124      |\n",
            "|    value_loss           | 75.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 199          |\n",
            "|    ep_rew_mean          | 275          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1158         |\n",
            "|    iterations           | 303          |\n",
            "|    time_elapsed         | 4286         |\n",
            "|    total_timesteps      | 4964352      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033917038 |\n",
            "|    clip_fraction        | 0.0392       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.464       |\n",
            "|    explained_variance   | 0.966        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 161          |\n",
            "|    n_updates            | 1208         |\n",
            "|    policy_gradient_loss | 0.00141      |\n",
            "|    value_loss           | 89.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 200          |\n",
            "|    ep_rew_mean          | 282          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1159         |\n",
            "|    iterations           | 304          |\n",
            "|    time_elapsed         | 4296         |\n",
            "|    total_timesteps      | 4980736      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023195143 |\n",
            "|    clip_fraction        | 0.028        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.469       |\n",
            "|    explained_variance   | 0.953        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 47.9         |\n",
            "|    n_updates            | 1212         |\n",
            "|    policy_gradient_loss | 0.000276     |\n",
            "|    value_loss           | 92.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 199         |\n",
            "|    ep_rew_mean          | 268         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1160        |\n",
            "|    iterations           | 305         |\n",
            "|    time_elapsed         | 4306        |\n",
            "|    total_timesteps      | 4997120     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003727625 |\n",
            "|    clip_fraction        | 0.0405      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.437      |\n",
            "|    explained_variance   | 0.946       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 40.3        |\n",
            "|    n_updates            | 1216        |\n",
            "|    policy_gradient_loss | -5.07e-05   |\n",
            "|    value_loss           | 190         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=5000000, episode_reward=282.03 +/- 16.75\n",
            "Episode length: 200.90 +/- 14.61\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 201          |\n",
            "|    mean_reward          | 282          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 5000000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029024915 |\n",
            "|    clip_fraction        | 0.039        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.467       |\n",
            "|    explained_variance   | 0.913        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 221          |\n",
            "|    n_updates            | 1220         |\n",
            "|    policy_gradient_loss | -0.000963    |\n",
            "|    value_loss           | 350          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 200      |\n",
            "|    ep_rew_mean     | 276      |\n",
            "| time/              |          |\n",
            "|    fps             | 1161     |\n",
            "|    iterations      | 306      |\n",
            "|    time_elapsed    | 4316     |\n",
            "|    total_timesteps | 5013504  |\n",
            "---------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z2o4wiUhtkq9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}