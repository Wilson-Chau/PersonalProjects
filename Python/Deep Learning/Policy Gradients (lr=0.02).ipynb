{"cells":[{"cell_type":"markdown","metadata":{"id":"HPlCynUOOdeX"},"source":["# Policy Gradients: REINFORCE Baseline with LunarLander"]},{"cell_type":"code","source":["# Install dependencies\n","!sudo apt-get update > /dev/null 2>&1\n","!sudo apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n","!pip install rarfile --quiet\n","!pip install stable-baselines3[extra] ale-py==0.7.4 --quiet\n","!pip install box2d-py --quiet\n","!pip install gym pyvirtualdisplay --quiet\n","!pip install pyglet --quiet"],"metadata":{"id":"x-GSMQpgOtQE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668950020673,"user_tz":-480,"elapsed":51281,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}},"outputId":"b75064ad-f6cc-4884-ea32-f19eb3a208b3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 170 kB 13.5 MB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 63.4 MB/s \n","\u001b[K     |████████████████████████████████| 1.5 MB 51.5 MB/s \n","\u001b[K     |████████████████████████████████| 237 kB 69.9 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 51 kB 6.5 MB/s \n","\u001b[?25h  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 448 kB 12.9 MB/s \n","\u001b[K     |████████████████████████████████| 966 kB 14.6 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":3,"metadata":{"scrolled":true,"id":"E1VTnHMKOdeZ","executionInfo":{"status":"ok","timestamp":1668950024314,"user_tz":-480,"elapsed":3654,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}}},"outputs":[],"source":["import io\n","import os\n","import glob\n","\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import gym\n","from gym import spaces\n","from gym.wrappers import Monitor"]},{"cell_type":"code","execution_count":4,"metadata":{"scrolled":true,"id":"N9wICiUwOdea","executionInfo":{"status":"ok","timestamp":1668950024316,"user_tz":-480,"elapsed":24,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}}},"outputs":[],"source":["# check and use GPU if available if not use CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"c34q50ZaOdea"},"source":["### LunarLander\n","\n","LunarLander is an OpenAI gym environment (env). In this env the agent tries to land a space craft safely on the ground by firing the main, left, or right engine. The agent receives a reward for navigating to the landing pad and turning off the engine, a large reward for a safe landing, a large negative reward for an unsafe landing, and a small negative reward for using the engines. There are discrete and continuous versions of LunarLander."]},{"cell_type":"code","source":["# @title Plotting/Video functions\n","from IPython.display import HTML\n","from pyvirtualdisplay import Display\n","from IPython import display as ipythondisplay\n","\n","display = Display(visible=0, size=(1400, 900))\n","display.start()\n","\n","\"\"\"\n","Utility functions to enable video recording of gym environment\n","and displaying it.\n","To enable video, just do \"env = wrap_env(env)\"\"\n","\"\"\"\n","\n","def show_video():\n","  mp4list = glob.glob('video/*.mp4')\n","  if len(mp4list) > 0:\n","    mp4 = mp4list[0]\n","    video = io.open(mp4, 'r+b').read()\n","    encoded = base64.b64encode(video)\n","    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","  else:\n","    print(\"Could not find video\")\n","\n","\n","def wrap_env(env):\n","  env = Monitor(env, './video', force=True)\n","  return env"],"metadata":{"id":"6xmA5zq5UTrL","executionInfo":{"status":"ok","timestamp":1668950024317,"user_tz":-480,"elapsed":24,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"vPyiEveoOdeb","executionInfo":{"status":"error","timestamp":1668950024317,"user_tz":-480,"elapsed":22,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}},"outputId":"556fe74f-7d4c-4c3a-da01-4a25e1fe3297"},"outputs":[{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-8167c4940daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LunarLander-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprev_screen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_screen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Making new env: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/box2d/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlunar_lander\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLunarLanderContinuous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbipedal_walker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBipedalWalker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBipedalWalkerHardcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcar_racing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCarRacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mBox2D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/envs/box2d/car_racing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseeding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEzPickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"debug_gl\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyglet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mMIN_PYTHON_VERSION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"pyglet {version} requires Python {MIN_PYTHON_VERSION_STR} or newer.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'sphinx'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: pyglet 2.0.0 requires Python 3.8 or newer."]}],"source":["env = gym.make('LunarLander-v2')\n","env.reset()\n","\n","prev_screen = env.render(mode='rgb_array')\n","plt.imshow(prev_screen)\n","\n","for i in range(200):\n","    env.render()\n","    action = env.action_space.sample()\n","    obs, reward, done, info = env.step(action)\n","    if done:\n","        env.reset()\n","        \n","env.close()"]},{"cell_type":"markdown","metadata":{"id":"J5wkMevgOdeb"},"source":["### Policy Gradient Methods\n","\n","In policy gradient methods, we update the policy directly. Ie we parameterize the policy and perform gradient descent updates on the policy parameters seeking to improve the policy. This is in contrast to section 3 where we learned estimates of the state or action-values. Then we extracted a policy based on those values, like with the epsilon greedy DQN policy.\n","\n","### Discrete vs. Continuous Action Spaces\n","\n","PG methods can work in discrete and continuous action spaces. The DQN method we went over in section three required discrete action spaces: ie a limited number of actions. In continuous actions spaces there are an infinite number of actions as the action can be any value in a range. Continuous action spaces are often parameterized by a probability distribution and we learn the parameters of the distribution. For example we assume the actions come from a Gaussian distribution and try to learn the mean and standard deviation of the Gaussian that leads to the best policy. \n","\n","### REINFORCE with Lunar Lander\n","\n","In this example, we will solve the discrete version of Lunar Lander using the REINFORCE with baseline method."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"y3Wd67ToOdec","executionInfo":{"status":"aborted","timestamp":1668950024318,"user_tz":-480,"elapsed":17,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}}},"outputs":[],"source":["class ActorNet(nn.Module):\n","    def __init__(self, state_size, action_size, hidden_size):\n","        super(ActorNet, self).__init__()\n","        self.dense_layer_1 = nn.Linear(state_size, hidden_size)\n","        self.dense_layer_2 = nn.Linear(hidden_size, hidden_size)\n","        self.output = nn.Linear(hidden_size, action_size)\n","    \n","    def forward(self, x):\n","        x = torch.clamp(x,-1.1,1.1)\n","        x = F.relu(self.dense_layer_1(x))\n","        x = F.relu(self.dense_layer_2(x))\n","        return F.softmax(self.output(x),dim=-1) #-1 to take softmax of last dimension\n","    \n","class ValueFunctionNet(nn.Module):\n","    def __init__(self, state_size, hidden_size):\n","        super(ValueFunctionNet, self).__init__()\n","        self.dense_layer_1 = nn.Linear(state_size, hidden_size)\n","        self.dense_layer_2 = nn.Linear(hidden_size, hidden_size)\n","        self.output = nn.Linear(hidden_size, 1)\n","    \n","    def forward(self, x):\n","        x = torch.clamp(x,-1.1,1.1)\n","        x = F.relu(self.dense_layer_1(x))\n","        x = F.relu(self.dense_layer_2(x))\n","        return self.output(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"scrolled":true,"id":"6Aui_bzwOdec","executionInfo":{"status":"aborted","timestamp":1668950024318,"user_tz":-480,"elapsed":17,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}}},"outputs":[],"source":["class PGAgent():\n","    def __init__(self, state_size, action_size, hidden_size, actor_lr, vf_lr, discount ):\n","        self.action_size = action_size\n","        self.actor_net = ActorNet(state_size, action_size, hidden_size).to(device)\n","        self.vf_net = ValueFunctionNet(state_size, hidden_size).to(device)\n","        self.actor_optimizer = optim.Adam(self.actor_net.parameters(), lr=actor_lr)\n","        self.vf_optimizer = optim.Adam(self.vf_net.parameters(), lr=vf_lr)\n","        self.discount = discount\n","        \n","    def select_action(self, state):\n","        #get action probs then randomly sample from the probabilities\n","        with torch.no_grad():\n","            input_state = torch.FloatTensor(state).to(device)\n","            action_probs = self.actor_net(input_state)\n","            #detach and turn to numpy to use with np.random.choice()\n","            action_probs = action_probs.detach().cpu().numpy()\n","            action = np.random.choice(np.arange(self.action_size), p=action_probs)\n","        return action\n","\n","    def train(self, state_list, action_list, reward_list):\n","        \n","        #turn rewards into return\n","        trajectory_len = len(reward_list)\n","        return_array = np.zeros((trajectory_len,))\n","        g_return = 0.\n","        for i in range(trajectory_len-1,-1,-1):\n","            g_return = reward_list[i] + self.discount*g_return\n","            return_array[i] = g_return\n","            \n","        # create tensors\n","        state_t = torch.FloatTensor(state_list).to(device)\n","        action_t = torch.LongTensor(action_list).to(device).view(-1,1)\n","        return_t = torch.FloatTensor(return_array).to(device).view(-1,1)\n","        \n","        # get value function estimates\n","        vf_t = self.vf_net(state_t).to(device)\n","        with torch.no_grad():\n","            advantage_t = return_t - vf_t\n","        \n","        # calculate actor loss\n","        selected_action_prob = self.actor_net(state_t).gather(1, action_t)\n","        # REINFORCE loss:\n","        #actor_loss = torch.mean(-torch.log(selected_action_prob) * return_t)\n","        # REINFORCE Baseline loss:\n","        actor_loss = torch.mean(-torch.log(selected_action_prob) * advantage_t)\n","        self.actor_optimizer.zero_grad()\n","        actor_loss.backward()\n","        self.actor_optimizer.step() \n","\n","        # calculate vf loss\n","        loss_fn = nn.MSELoss()\n","        vf_loss = loss_fn(vf_t, return_t)\n","        self.vf_optimizer.zero_grad()\n","        vf_loss.backward()\n","        self.vf_optimizer.step() \n","        \n","        return actor_loss.detach().cpu().numpy(), vf_loss.detach().cpu().numpy()\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"scrolled":true,"id":"iqdbYqC7Oded","executionInfo":{"status":"aborted","timestamp":1668950024318,"user_tz":-480,"elapsed":17,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}}},"outputs":[],"source":["# initialize environment\n","env = gym.make('LunarLander-v2')\n","action_size = env.action_space.n\n","state_size = env.observation_space.shape[0]\n","\n","# set seed\n","seed = 31\n","env.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","# hyperparameters\n","episodes = 1000 # run agent for this many episodes\n","hidden_size = 128 # number of units in NN hidden layers\n","actor_lr = 0.001 # learning rate for actor\n","value_function_lr = 0.001 # learning rate for value function\n","discount = 0.99 # discount factor gamma value\n","reward_scale = 0.01 #scale reward by this amount\n","\n","# create agent\n","agent = PGAgent(state_size, action_size, hidden_size, actor_lr, value_function_lr, discount)"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"7p_z-Bd7Oded","executionInfo":{"status":"aborted","timestamp":1668950024319,"user_tz":-480,"elapsed":18,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}}},"outputs":[],"source":["stats_rewards_list = [] # store stats for plotting in this\n","stats_every = 10 # print stats every this many episodes\n","total_reward = 0\n","timesteps = 0\n","episode_length = 0\n","stats_actor_loss, stats_vf_loss = 0., 0.\n","\n","for ep in range(episodes):\n","    state = env.reset()\n","    state_list, action_list, reward_list = [], [], []\n","    \n","    # stopping condition for training if agent reaches the amount of reward\n","    if len(stats_rewards_list) > stats_every and np.mean(stats_rewards_list[-stats_every:],axis=0)[1] > 190:\n","        print(\"Stopping at episode {} with average rewards of {} in last {} episodes\".\n","            format(ep, np.mean(stats_rewards_list[-stats_every:],axis=0)[1], stats_every))\n","        break  \n","\n","    # train in each episode until episode is done\n","    while True:\n","        timesteps += 1\n","        #env.render()\n","        # select an action from the agent's policy\n","        action = agent.select_action(state)\n","        \n","        # enter action into the env\n","        next_state, reward, done, _ = env.step(action)\n","        total_reward += reward\n","        episode_length += 1\n","        # store agent's trajectory\n","        state_list.append(state)\n","        action_list.append(action)\n","        reward_list.append(reward*reward_scale)\n","        \n","        # end episode early\n","        if total_reward < -250:\n","            done = 1\n","        \n","        if done:\n","            actor_loss, vf_loss = agent.train(state_list, action_list, reward_list)\n","            stats_rewards_list.append((ep, total_reward, episode_length))\n","            stats_actor_loss += actor_loss\n","            stats_vf_loss += vf_loss\n","            total_reward = 0\n","            episode_length = 0  \n","            if ep % stats_every == 0:\n","                print('Episode: {}'.format(ep),\n","                    'Timestep: {}'.format(timesteps),\n","                    'Total reward: {:.1f}'.format(np.mean(stats_rewards_list[-stats_every:],axis=0)[1]),\n","                    'Episode length: {:.1f}'.format(np.mean(stats_rewards_list[-stats_every:],axis=0)[2]),\n","                    'Actor Loss: {:.4f}'.format(stats_actor_loss/stats_every), \n","                    'VF Loss: {:.4f}'.format(stats_vf_loss/stats_every))\n","                stats_actor_loss, stats_vf_loss = 0., 0.\n","            break\n","        \n","        state = next_state\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"dcwjHF4mOdee","executionInfo":{"status":"aborted","timestamp":1668950024319,"user_tz":-480,"elapsed":17,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}}},"outputs":[],"source":["# plot stats\n","def get_running_stat(stat, stat_len):\n","    cum_sum = np.cumsum(np.insert(stat, 0, 0)) \n","    return (cum_sum[stat_len:] - cum_sum[:-stat_len]) / stat_len\n","\n","episode, r, l = np.array(stats_rewards_list).T\n","cum_r = get_running_stat(r, 10)\n","cum_l = get_running_stat(l, 10)\n","\n","# plot rewards\n","plt.plot(episode[-len(cum_r):], cum_r)\n","plt.plot(episode, r, alpha=0.5)\n","plt.xlabel('Episode')\n","plt.ylabel('Episode Reward')"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"FUWStA6YOdee","executionInfo":{"status":"aborted","timestamp":1668950024320,"user_tz":-480,"elapsed":18,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}}},"outputs":[],"source":["# plot episode lengths\n","plt.plot(episode[-len(cum_l):], cum_l)\n","plt.plot(episode, l, alpha=0.5)\n","plt.xlabel('Episode')\n","plt.ylabel('Episode Length')"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"SLJrtnYDOdee","executionInfo":{"status":"aborted","timestamp":1668950024320,"user_tz":-480,"elapsed":18,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}}},"outputs":[],"source":["from google.colab import files\n","# plot rewards\n","plt.plot(episode[-len(cum_r):], cum_r)\n","plt.plot(episode, r, alpha=0.5)\n","plt.xlabel('Episode')\n","plt.ylabel('Episode Reward')\n","\n","plt.savefig(fname=\"PG.png\")\n","files.download(\"PG.png\")"]},{"cell_type":"code","source":[],"metadata":{"id":"Qystat_QrX_y","executionInfo":{"status":"aborted","timestamp":1668950024321,"user_tz":-480,"elapsed":18,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9qvG8jK7uR7G","executionInfo":{"status":"aborted","timestamp":1668950024321,"user_tz":-480,"elapsed":18,"user":{"displayName":"Shi Ming Jasmine KWOK","userId":"06495048235925787994"}}},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"rl_pytorch","language":"python","name":"rl_pytorch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}